<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Redis]]></title>
    <url>%2F2022%2F04%2F07%2FRedis%2F</url>
    <content type="text"><![CDATA[一、数据结构1.1 基础数据结构1.1.1 String 简介:String是Redis最基础的数据结构类型，它是二进制安全的，可以存储图片或者序列化的对象，值最大存储为512M 简单使用举例: set key value、get key等 应用场景：共享session、分布式锁，计数器、限流。 内部编码有3种，int（8字节长整型）/embstr（小于等于39字节字符串）/raw（大于39个字节字符串） 1.1.2 Hash 简介：在Redis中，哈希类型是指v（值）本身又是一个键值对（k-v）结构 简单使用举例：hset key field value 、hget key field 内部编码：ziplist（压缩列表） 、hashtable（哈希表） 应用场景：缓存用户信息等。 注意点：如果开发使用hgetall，哈希元素比较多的话，可能导致Redis阻塞，可以使用hscan。而如果只是获取部分field，建议使用hmget。 1.1.3 List 简介：列表（list）类型是用来存储多个有序的字符串，一个列表最多可以存储2^32-1个元素。 简单实用举例：lpush key value [value …] 、lrange key start end 内部编码：ziplist（压缩列表）、linkedlist（链表） 应用场景：消息队列，文章列表 list应用场景参考以下： lpush+lpop=Stack（栈） lpush+rpop=Queue（队列） lpsh+ltrim=Capped Collection（有限集合） lpush+brpop=Message Queue（消息队列） 1.1.4 Set 简介：集合（set）类型也是用来保存多个的字符串元素，但是不允许重复元素 简单使用举例：sadd key element [element …]、smembers key 内部编码：intset（整数集合）、hashtable（哈希表） 注意点：smembers和lrange、hgetall都属于比较重的命令，如果元素过多存在阻塞Redis的可能性，可以使用sscan来完成。 应用场景：用户标签,生成随机数抽奖、社交需求。 1.1.5 SortedSort 简介：已排序的字符串集合，同时元素不能重复 简单格式举例：zadd key score member [score member …]，zrank key member 底层内部编码：ziplist（压缩列表）、skiplist（跳跃表） 应用场景：排行榜，社交需求（如用户点赞）。 1.2 拓展数据结构1.2.1 GeospatialRedis3.2推出的，地理位置定位，用于存储地理位置信息，并对存储的信息进行操作。 1.2.2 Hyperloglog用来做基数统计算法的数据结构，如统计网站的UV 1.2.3 Bitmap用一个比特位来映射某个元素的状态，在Redis中，它的底层是基于字符串类型实现的，可以把bitmaps成作一个以比特位为单位的数组 二、过期策略、内存淘汰机制2.1 过期策略我们在set key的时候，可以给它设置一个过期时间，比如expire key 60。指定这key60s后过期，60s后，redis该如何处理？常见几种过期策略如下： 2.1.1 定时过期每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即对key进行清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。 2.1.2 惰性过期只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。 2.1.3 定期过期每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。 expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。 Redis中同时使用了惰性过期和定期过期两种过期策略。 假设Redis当前存放30万个key，并且都设置了过期时间，如果你每隔100ms就去检查这全部的key，CPU负载会特别高，最后可能会挂掉。 因此，redis采取的是定期过期，每隔100ms就随机抽取一定数量的key来检查和删除的。 但是呢，最后可能会有很多已经过期的key没被删除。这时候，redis采用惰性删除。在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间并且已经过期了，此时就会删除。 2.2 内存淘汰机制 volatile-lru：当内存不足以容纳新写入数据时，从设置了过期时间的key中使用LRU（最近最少使用）算法进行淘汰； allkeys-lru：当内存不足以容纳新写入数据时，从所有key中使用LRU（最近最少使用）算法进行淘汰。 volatile-lfu：4.0版本新增，当内存不足以容纳新写入数据时，在过期的key中，使用LFU算法进行删除key。 allkeys-lfu：4.0版本新增，当内存不足以容纳新写入数据时，从所有key中使用LFU算法进行淘汰； volatile-random：当内存不足以容纳新写入数据时，从设置了过期时间的key中，随机淘汰数据；。 allkeys-random：当内存不足以容纳新写入数据时，从所有key中随机淘汰数据。 volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的key中，根据过期时间进行淘汰，越早过期的优先被淘汰； noeviction：默认策略，当内存不足以容纳新写入数据时，新写入操作会报错。 三、持久化机制Redis是基于内存的非关系型K-V数据库，既然它是基于内存的，如果Redis服务器挂了，数据就会丢失。为了避免数据丢失了，Redis提供了持久化，即把数据保存到磁盘。 3.1 RDBRDB持久化机制，对redis中的数据执行周期性的持久化 3.1.1 工作流程 redis根据配置自己尝试去生成rdb快照文件 fork一个子进程出来 子进程尝试将数据dump到临时的rdb快照文件中 完成rdb快照文件的生成之后，就替换之前的旧的快照文件 3.1.2 优点1）RDB会生成多个数据文件，每个数据文件都代表了某一个时刻中redis的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说Amazon的S3云服务上去，在国内可以是阿里云的ODPS分布式存储上，以预定好的备份策略来定期备份redis中的数据。RDB也可以做冷备，生成多个文件，每个文件都代表了某一个时刻的完整的数据快照。AOF也可以做冷备，只有一个文件，但是你可以，每隔一定时间，去copy一份这个文件出来RDB做冷备，优势在哪儿呢？由redis去控制固定时长生成快照文件的事情，比较方便; AOF，还需要自己写一些脚本去做这个事情，各种定时 RDB数据做冷备，在最坏的情况下，提供数据恢复的时候，速度比AOF快 2）RDB对redis对外提供的读写服务，影响非常小，可以让redis保持高性能，因为redis主进程只需要fork一个子进程，让子进程执行磁盘IO操作来进行RDB持久化即可 RDB，每次写，都是直接写redis内存，只是在一定的时候，才会将数据写入磁盘中 AOF，每次都是要写文件的，虽然可以快速写入os cache中，但是还是有一定的时间开销的,速度肯定比RDB略慢一些 3）相对于AOF持久化机制来说，直接基于RDB数据文件来重启和恢复redis进程，更加快速 AOF，存放的指令日志，做数据恢复的时候，其实是要回放和执行所有的指令日志，来恢复出来内存中的所有数据的RDB，就是一份数据文件，恢复的时候，直接加载到内存中即可 3.1.3 缺点1）如果想要在redis故障时，尽可能少的丢失数据，那么RDB没有AOF好。一般来说，RDB数据快照文件，都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦redis进程宕机，那么会丢失最近5分钟的数据 这个问题，也是rdb最大的缺点，就是不适合做第一优先的恢复方案，如果你依赖RDB做第一优先恢复方案，会导致数据丢失的比较多 2）RDB每次在fork子进程来执行RDB快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒 一般不要让RDB的间隔太长，否则每次生成的RDB文件太大了，对redis本身的性能可能会有影响的 3.2 AOF3.2.1 优点（1）AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据 每隔1秒，就执行一次fsync操作，保证os cache中的数据写入磁盘中 redis进程挂了，最多丢掉1秒钟的数据 （2）AOF日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复 （3）AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewrite log的时候，会对其中的指导进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的merge后的日志文件ready的时候，再交换新老日志文件即可。 （4）AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据 3.2.2 缺点对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大 AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的，如果你要保证一条数据都不丢，也是可以的，AOF的fsync设置成没写入一条数据，fsync一次，那就完蛋了，redis的QPS大降 以前AOF发生过bug，就是通过AOF记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似AOF这种较为复杂的基于命令日志/merge/回放的方式，比基于RDB每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有bug。不过AOF就是为了避免rewrite过程导致的bug，因此每次rewrite并不是基于旧的指令日志进行merge的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。 唯一的比较大的缺点，其实就是做数据恢复的时候，会比较慢，还有做冷备，定期的备份，不太方便，可能要自己手写复杂的脚本去做，做冷备不太合适 3.3 如何选择持久化 不要仅仅使用RDB，因为那样会导致丢失很多数据 也不要仅仅使用AOF，因为那样有两个问题，第一，通过AOF做冷备，没有RDB做冷备，来的恢复速度更快; 第二，RDB每次简单粗暴生成数据快照，更加健壮，可以避免AOF这种复杂的备份和恢复机制的bug 综合使用AOF和RDB两种持久化机制，用AOF来保证数据不丢失，作为数据恢复的第一选择; 用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复 四、Redis 主从4.1 主从服务主从模式中，Redis部署了多台机器，有主节点，负责读写操作，有从节点，只负责读操作。从节点的数据来自主节点，实现原理就是主从复制机制。 主从复制包括全量复制，增量复制两种。一般当slave第一次启动连接master，或者认为是第一次连接，就采用全量复制，全量复制流程如下： slave发送sync命令到master。 master接收到SYNC命令后，执行bgsave命令，生成RDB全量文件。 master使用缓冲区，记录RDB快照生成期间的所有写命令。 master执行完bgsave后，向所有slave发送RDB快照文件。 slave收到RDB快照文件后，载入、解析收到的快照。 master使用缓冲区，记录RDB同步期间生成的所有写的命令。 master快照发送完毕后，开始向slave发送缓冲区中的写命令; salve接受命令请求，并执行来自master缓冲区的写命令 redis2.8版本之后，已经使用psync来替代sync，因为sync命令非常消耗系统资源，psync的效率更高。 slave与master全量同步之后，master上的数据，如果再次发生更新，就会触发增量复制。 当master节点发生数据增减时，就会触发replicationFeedSalves()函数，接下来在 Master节点上调用的每一个命令会使用replicationFeedSlaves()来同步到Slave节点。执行此函数之前呢，master节点会判断用户执行的命令是否有数据更新，如果有数据更新的话，并且slave节点不为空，就会执行此函数。这个函数作用就是：把用户执行的命令发送到所有的slave节点，让slave节点执行。 4.2 Redis哨兵主从模式中，一旦主节点由于故障不能提供服务，需要人工将从节点晋升为主节点，同时还要通知应用方更新主节点地址。显然，多数业务场景都不能接受这种故障处理方式。Redis从2.8开始正式提供了Redis Sentinel（哨兵）架构来解决这个问题。 哨兵模式，由一个或多个Sentinel实例组成的Sentinel系统，它可以监视所有的Redis主节点和从节点，并在被监视的主节点进入下线状态时，自动将下线主服务器属下的某个从节点升级为新的主节点。但是呢，一个哨兵进程对Redis节点进行监控，就可能会出现问题（单点问题），因此，可以使用多个哨兵来进行监控Redis节点，并且各个哨兵之间还会进行监控。 简单来说，哨兵模式就三个作用： 发送命令，等待Redis服务器（包括主服务器和从服务器）返回监控其运行状态； 哨兵监测到主节点宕机，会自动将从节点切换成主节点，然后通过发布订阅模式通知其他的从节点，修改配置文件，让它们切换主机； 哨兵之间还会相互监控，从而达到高可用。 故障切换的过程： 假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行 failover 过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为主观下线。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行 failover 操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为客观下线。这样对于客户端而言，一切都是透明的。 哨兵的工作模式如下： 每个Sentinel以每秒钟一次的频率向它所知的Master，Slave以及其他Sentinel实例发送一个 PING命令。 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel标记为主观下线。 如果一个Master被标记为主观下线，则正在监视这个Master的所有 Sentinel 要以每秒一次的频率确认Master的确进入了主观下线状态。 当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认Master的确进入了主观下线状态， 则Master会被标记为客观下线。 在一般情况下， 每个 Sentinel 会以每10秒一次的频率向它已知的所有Master，Slave发送 INFO 命令。 当Master被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次 若没有足够数量的 Sentinel同意Master已经下线， Master的客观下线状态就会被移除；若Master 重新向 Sentinel 的 PING 命令返回有效回复， Master 的主观下线状态就会被移除。 五、Redis Cluster哨兵模式基于主从模式，实现读写分离，它还可以自动切换，系统可用性更高。但是它每个节点存储的数据是一样的，浪费内存，并且不好在线扩容。因此，Cluster集群应运而生，它在Redis3.0加入的，实现了Redis的分布式存储。对数据进行分片，也就是说每台Redis节点上存储不同的内容，来解决在线扩容的问题。并且，它也提供复制和故障转移的功能。 5.1 Cluster之间的通信一个Redis集群由多个节点组成，各个节点之间是怎么通信的呢？通过Gossip协议！ Redis Cluster集群通过Gossip协议进行通信，节点之前不断交换信息，交换的信息内容包括节点出现故障、新节点加入、主从节点变更信息、slot信息等等。常用的Gossip消息分为4种，分别是：ping、pong、meet、fail。 meet消息：通知新节点加入。消息发送者通知接收者加入到当前集群，meet消息通信正常完成后，接收节点会加入到集群中并进行周期性的ping、pong消息交换。 ping消息：集群内交换最频繁的消息，集群内每个节点每秒向多个其他节点发送ping消息，用于检测节点是否在线和交换彼此状态信息。 pong消息：当接收到ping、meet消息时，作为响应消息回复给发送方确认消息正常通信。pong消息内部封装了自身状态数据。节点也可以向集群内广播自身的pong消息来通知整个集群对自身状态进行更新。 fail消息：当节点判定集群内另一个节点下线时，会向集群内广播一个fail消息，其他节点接收到fail消息之后把对应节点更新为下线状态。 特别的，每个节点是通过集群总线(cluster bus) 与其他的节点进行通信的。通讯时，使用特殊的端口号，即对外服务端口号加10000。例如如果某个node的端口号是6379，那么它与其它nodes通信的端口号是 16379。nodes 之间的通信采用特殊的二进制协议。 5.2 Hash Slot插槽算法既然是分布式存储，Cluster集群使用的分布式算法是一致性Hash嘛？并不是，而是Hash Slot插槽算法。 插槽算法把整个数据库被分为16384个slot（槽），每个进入Redis的键值对，根据key进行散列，分配到这16384插槽中的一个。使用的哈希映射也比较简单，用CRC16算法计算出一个16 位的值，再对16384取模。数据库中的每个键都属于这16384个槽的其中一个，集群中的每个节点都可以处理这16384个槽。 集群中的每个节点负责一部分的hash槽，比如当前集群有A、B、C个节点，每个节点上的哈希槽数 =16384/3，那么就有： 节点A负责0~5460号哈希槽 节点B负责5461~10922号哈希槽 节点C负责10923~16383号哈希槽 5.3 Redis Cluster集群Redis Cluster集群中，需要确保16384个槽对应的node都正常工作，如果某个node出现故障，它负责的slot也会失效，整个集群将不能工作。 因此为了保证高可用，Cluster集群引入了主从复制，一个主节点对应一个或者多个从节点。当其它主节点 ping 一个主节点 A 时，如果半数以上的主节点与 A 通信超时，那么认为主节点 A 宕机了。如果主节点宕机时，就会启用从节点。 在Redis的每一个节点上，都有两个玩意，一个是插槽（slot），它的取值范围是0~16383。另外一个是cluster，可以理解为一个集群管理的插件。当我们存取的key到达时，Redis 会根据CRC16算法得出一个16 bit的值，然后把结果对16384取模。酱紫每个key都会对应一个编号在 0~16383 之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。 虽然数据是分开存储在不同节点上的，但是对客户端来说，整个集群Cluster，被看做一个整体。客户端端连接任意一个node，看起来跟操作单实例的Redis一样。当客户端操作的key没有被分配到正确的node节点时，Redis会返回转向指令，最后指向正确的node，这就有点像浏览器页面的302 重定向跳转 5.4 故障转移Redis集群实现了高可用，当集群内节点出现故障时，通过故障转移，以保证集群正常对外提供服务。 redis集群通过ping/pong消息，实现故障发现。这个环境包括主观下线和客观下线。 主观下线： 某个节点认为另一个节点不可用，即下线状态，这个状态并不是最终的故障判定，只能代表一个节点的意见，可能存在误判情况。 客观下线： 指标记一个节点真正的下线，集群内多个节点都认为该节点不可用，从而达成共识的结果。如果是持有槽的主节点故障，需要为该节点进行故障转移。 假如节点A标记节点B为主观下线，一段时间后，节点A通过消息把节点B的状态发到其它节点，当节点C接受到消息并解析出消息体时，如果发现节点B的pfail状态时，会触发客观下线流程； 当下线为主节点时，此时Redis Cluster集群为统计持有槽的主节点投票，看投票数是否达到一半，当下线报告统计数大于一半时，被标记为客观下线状态。 故障恢复：故障发现后，如果下线节点的是主节点，则需要在它的从节点中选一个替换它，以保证集群的高可用。流程如下： 资格检查：检查从节点是否具备替换故障主节点的条件。 准备选举时间：资格检查通过后，更新触发故障选举时间。 发起选举：到了故障选举时间，进行选举。 选举投票：只有持有槽的主节点才有票，从节点收集到足够的选票（大于一半），触发替换主节点操作 六、分布式锁分布式锁里面细节挺多的，我用商品抢购，库存扣减例子，来演示一下各种方案可能出现的问题，以及相应的解决方案。 6.1 当不使用分布式锁的时候123456789101112131415161718192021222324252627282930313233343536373839@Autowired private StringRedisTemplate redisTemplate; /** * 假设这次卖的是Iphone13 */ private static final String STOCK_KEY = "stock:iphone13"; /** * 分布式锁 */ private static final String STOCK_IPHONE_LOCK = "stock:iphone13:lock"; /** * 当前版本的库存扣减，如果是单实例，是可以的 * 但是目前基本都是k8s多实例部署，如果使用这种代码，在并发比较高的时候， * 多个实例可能同时执行到进入锁后，拿到key的值是相同的 * 这个时候可能就会出现重复扣减的问题，会出现严重的不一致问题，体现在业务场景，也就是超卖了 * * @return */ @PostMapping("v1/deductStock") public String deductStockV1() &#123; synchronized (this) &#123; String stockValue = redisTemplate.opsForValue().get(STOCK_KEY); if (Objects.nonNull(stockValue)) &#123; //获取当前库存 int stock = Integer.parseInt(stockValue); if (stock &gt; 0) &#123; stock--; redisTemplate.opsForValue().set(STOCK_KEY, String.valueOf(stock)); System.out.println("deduct stock success"); &#125; else &#123; System.out.println("deduct stock fail"); &#125; &#125; &#125; return "ok"; &#125; 6.2 setNx命令123456789101112131415161718192021222324252627282930313233/** * 这个版本的库存扣减，可以保证在多实例的情况下，库存不会出现超卖的问题了，但是还是会有问题 * 考虑这种场景：拿到了这把锁之后，如果系统发生了crash，没有执行到finally的代码，那么这把锁就永远留在了redis里面 * 那后续所有的线程都无法获取到锁，进行库存的扣减了 * * @return */ @PostMapping("v2/deductStock") public String deductStockV2() &#123; try &#123; //试图加锁, setIfAbsent就是 setNx命令，这是RedisTemplate的api，如果使用jedis，就直接是调用setNx命令 Boolean lockSuccess = redisTemplate.opsForValue().setIfAbsent(STOCK_IPHONE_LOCK, "HAHA，I GET THIS LOCK"); if (!lockSuccess) &#123; return "没有抢到商品，请稍后重试"; &#125; String stockValue = redisTemplate.opsForValue().get(STOCK_KEY); if (Objects.nonNull(stockValue)) &#123; //获取当前库存 int stock = Integer.parseInt(stockValue); if (stock &gt; 0) &#123; stock--; redisTemplate.opsForValue().set(STOCK_KEY, String.valueOf(stock)); System.out.println("deduct stock success"); &#125; else &#123; System.out.println("deduct stock fail"); &#125; &#125; &#125; finally &#123; //扣减库存成功后，需要删除掉这把锁 redisTemplate.delete(STOCK_IPHONE_LOCK); &#125; return "ok"; &#125; 6.3 setEx命令123456789101112131415161718192021222324252627282930313233343536/** * 为了解决V2版本的分布式锁出现的问题，我们可以考虑使用Redis的setNxEx命令 * 就是这个key多久之后自动过期，这样即使没有执行到delete发生了crash，这个key过一段时间后，还是会自动过期的 * but 虽然解决了key一直存在的问题，但这个方法其实还是有问题的。 * 想象一下这种场景：如果加完锁后，接来下的代码执行时间过长，导致还没有执行到del语句，这个key就过期了呢，这就会很危险了 * 在线程很多的时候，这个锁基本就等于失效了 * * @return */ @PostMapping("v3/deductStock") public String deductStockV3() &#123; try &#123; //试图加锁 Boolean lockSuccess = redisTemplate.opsForValue().setIfAbsent(STOCK_IPHONE_LOCK, "HAHA，I GET THIS LOCK", 10, TimeUnit.SECONDS); if (Boolean.FALSE.equals(lockSuccess)) &#123; return "没有抢到商品，请稍后重试"; &#125; String stockValue = redisTemplate.opsForValue().get(STOCK_KEY); if (Objects.nonNull(stockValue)) &#123; //获取当前库存 int stock = Integer.parseInt(stockValue); if (stock &gt; 0) &#123; stock--; redisTemplate.opsForValue().set(STOCK_KEY, String.valueOf(stock)); System.out.println("deduct stock success"); &#125; else &#123; System.out.println("deduct stock fail"); &#125; &#125; &#125; finally &#123; //扣减库存成功后，需要删除掉这把锁 redisTemplate.delete(STOCK_IPHONE_LOCK); &#125; return "ok"; &#125; 6.4 Redisson机制Redisson的具体Api，可以参照官方示例来写,本身的原理，网上也有很多相关的示例图，可以看下图: 12345678910111213141516171819202122232425262728293031323334353637/** * 这个版本的分布式锁，引入了redisson进行分布式锁 * 这个分布式锁，他的原理在于加锁的同时，起了一个新的线程，定时的去对这个锁进行观察，如果发现他仍在运行，就将这个锁的超时时间进行续约 */ @PostMapping("v4/deductStock") public String deductStockV4() throws InterruptedException &#123; //RedissonClient演示做的临时创建，实际使用的时候，将他做成Java Bean注入进来 Config config = new Config(); config.useSingleServer() .setAddress("redis://127.0.0.1:6379"); RedissonClient client = Redisson.create(config); RLock lock = client.getLock(STOCK_IPHONE_LOCK); //这里使用了redssion的相关锁，他本身会启动一个watchDog看门狗的机制，当锁中的代码没有执行完时，自动对锁续约 boolean res = lock.tryLock(100, 10, TimeUnit.SECONDS); if (res) &#123; try &#123; String stockValue = redisTemplate.opsForValue().get(STOCK_KEY); if (Objects.nonNull(stockValue)) &#123; //获取当前库存 int stock = Integer.parseInt(stockValue); if (stock &gt; 0) &#123; stock--; redisTemplate.opsForValue().set(STOCK_KEY, String.valueOf(stock)); System.out.println("deduct stock success"); &#125; else &#123; System.out.println("deduct stock fail"); &#125; &#125; &#125; finally &#123; lock.unlock(); &#125; &#125; else &#123; System.out.println("没有争抢到锁，直接返回"); return "请稍后重试"; &#125; return "ok"; &#125; 6.4 RedLock+Redisson如果去问面试八股文，还会有人会提到Redlock，这个东西我是这样理解的，Redis官方提出了一种叫做redlock的分布式锁算法，redlock主要解决的是在多实例分布下实例failover的情况下，锁的可用性问题，每种语言都可以基于这种规范去实现自己语言的加锁方式，而在Java中，redisson实现了这个思路，但是，我去翻最新的文档，他是这样说的： 8.4. RedLock This object is deprecated. RLock operations now propagated to all Redis slaves. 所以说八股文还是会有一定的落后性 ：） 当然Redlock算法本身我们还是需要了解的，这里给出解释。而在日常使用Java中加锁，我个人理解Redisson是可以满足需求的。 Redlock的核心思想在于： In the distributed version of the algorithm we assume we have N Redis masters. Those nodes are totally independent, so we don’t use replication or any other implicit coordination system. We already described how to acquire and release the lock safely in a single instance. We take for granted that the algorithm will use this method to acquire and release the lock in a single instance. In our examples we set N=5, which is a reasonable value, so we need to run 5 Redis masters on different computers or virtual machines in order to ensure that they’ll fail in a mostly independent way. In order to acquire the lock, the client performs the following operations: It gets the current time in milliseconds. It tries to acquire the lock in all the N instances sequentially, using the same key name and random value in all the instances. During step 2, when setting the lock in each instance, the client uses a timeout which is small compared to the total lock auto-release time in order to acquire it. For example if the auto-release time is 10 seconds, the timeout could be in the ~ 5-50 milliseconds range. This prevents the client from remaining blocked for a long time trying to talk with a Redis node which is down: if an instance is not available, we should try to talk with the next instance ASAP. The client computes how much time elapsed in order to acquire the lock, by subtracting from the current time the timestamp obtained in step 1. If and only if the client was able to acquire the lock in the majority of the instances (at least 3), and the total time elapsed to acquire the lock is less than lock validity time, the lock is considered to be acquired. If the lock was acquired, its validity time is considered to be the initial validity time minus the time elapsed, as computed in step 3. If the client failed to acquire the lock for some reason (either it was not able to lock N/2+1 instances or the validity time is negative), it will try to unlock all the instances (even the instances it believed it was not able to lock). 中文翻译一下： 获取当前时间，以毫秒为单位。 按顺序向5个master节点请求加锁。客户端设置网络连接和响应超时时间，并且超时时间要小于锁的失效时间。（假设锁自动失效时间为10秒，则超时时间一般在5-50毫秒之间,我们就假设超时时间是50ms吧）。如果超时，跳过该master节点，尽快去尝试下一个master节点。 客户端使用当前时间减去开始获取锁时间（即步骤1记录的时间），得到获取锁使用的时间。当且仅当超过一半（N/2+1，这里是5/2+1=3个节点）的Redis master节点都获得锁，并且使用的时间小于锁失效时间时，锁才算获取成功。（如上图，10s&gt; 30ms+40ms+50ms+4m0s+50ms） 如果取到了锁，key的真正有效时间就变啦，需要减去获取锁所使用的时间。 如果获取锁失败（没有在至少N/2+1个master实例取到锁，有或者获取锁时间已经超过了有效时间），客户端要在所有的master节点上解锁（即便有些master节点根本就没有加锁成功，也需要解锁，以防止有些漏网之鱼）。 简化下步骤就是： 按顺序向5个master节点请求加锁 根据设置的超时时间来判断，是不是要跳过该master节点。 如果大于等于3个节点加锁成功，并且使用的时间小于锁的有效期，即可认定加锁成功啦。 如果获取锁失败，解锁！ 七、缓存与数据库一致性八、缓存使用的各种问题8.1 缓存击穿缓存击穿： 指热点key在某个时间点过期的时候，而恰好在这个时间点对这个Key有大量的并发请求过来，从而大量的请求打到db。 缓存击穿看着有点像，其实它两区别是，缓存雪崩是指数据库压力过大甚至down机，缓存击穿只是大量并发请求到了DB数据库层面。可以认为击穿是缓存雪崩的一个子集吧。有些文章认为它俩区别，是区别在于击穿针对某一热点key缓存，雪崩则是很多key。 解决方案就有两种： 使用互斥锁方案。缓存失效时，不是立即去加载db数据，而是先使用某些带成功返回的原子操作命令，如(Redis的setnx）去操作，成功的时候，再去加载db数据库数据和设置缓存。否则就去重试获取缓存。 永不过期，是指没有设置过期时间，但是热点数据快要过期时，异步线程去更新和设置过期时间。 8.2 缓存穿透缓存穿透：指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，进而给数据库带来压力。 通俗点说，读请求访问时，缓存和数据库都没有某个值，这样就会导致每次对这个值的查询请求都会穿透到数据库，这就是缓存穿透。 缓存穿透一般都是这几种情况产生的： 业务不合理的设计，比如大多数用户都没开守护，但是你的每个请求都去缓存，查询某个userid查询有没有守护。 业务/运维/开发失误的操作，比如缓存和数据库的数据都被误删除了。 黑客非法请求攻击，比如黑客故意捏造大量非法请求，以读取不存在的业务数据。 如何避免缓存穿透呢？ 一般有三种方法。 如果是非法请求，我们在API入口，对参数进行校验，过滤非法值。 如果查询数据库为空，我们可以给缓存设置个空值，或者默认值。但是如有有写请求进来的话，需要更新缓存哈，以保证缓存一致性，同时，最后给缓存设置适当的过期时间。（业务上比较常用，简单有效） 使用布隆过滤器快速判断数据是否存在。即一个查询请求过来时，先通过布隆过滤器判断值是否存在，存在才继续往下查。 布隆过滤器原理：它由初始值为0的位图数组和N个哈希函数组成。一个对一个key进行N个hash算法获取N个值，在比特数组中将这N个值散列后设定为1，然后查的时候如果特定的这几个位置都为1，那么布隆过滤器判断该key存在。 8.3 缓存雪崩缓存雪奔： 指缓存中数据大批量到过期时间，而查询数据量巨大，请求都直接访问数据库，引起数据库压力过大甚至down机。 缓存雪奔一般是由于大量数据同时过期造成的，对于这个原因，可通过均匀设置过期时间解决，即让过期时间相对离散一点。如采用一个较大固定值+一个较小的随机值，5小时+0到1800秒。 Redis 故障宕机也可能引起缓存雪崩。这就需要构造Redis高可用集群啦。]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring知识点总结]]></title>
    <url>%2F2021%2F11%2F30%2FSpring%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[一、版本特性1.1 Spring 4 泛型限定式依赖注入 核心容器的改进 web开发增强 集成Bean Validation 1.1（JSR-349）到SpringMVC Groovy Bean定义DSL 更好的Java泛型操作API JSR310日期API的支持 注解、脚本、任务、MVC等其他特性改进 1.2 Spring 5 JDK8的增强 核心容器的改进 新的SpringWebFlux模块 测试方面的改进 二、Spring 包含的模块Spring的包含如下几个核心子模块，这些模块构成了Spring应用的基石，基于此，还可以有更多的延伸以及根据需要添加的依赖 2.1 spring-core提供了框架的基本组成部分，包括控制翻转(Inversion of Control, IOC)和依赖注入(Dependency Injection, DI)功能。他的主要类和作用如下。 2.2.1、基础设施工具类（spring框架基础部分的核心工具类）ClassUtils ：Class的类加载 、查找类全部信息、类信息的处理等ObjectUtilsTest：基本类型的比较或数组比较，如果认为两个数组是相等的PatternMatchUtils：模式匹配 xx 模式匹配 、xx 、xx 、xx 、xx*yPropertyPlaceholderHelper:解析文本中占位符并替换成属性值ReflectionUtils：非常好用的反射类，得到字段、方法及过滤方法和方法回调ResourceUtils：这个解析定位资源非常好用 比如 classpath–URL–&gt;FileSerializationUtils：序列化工具SystemPropertyUtils:使用系统环境变量值替换占位符来生成字符串AnnotationUtils:注解工具类 想要解析注解请找它，绝对给力。BridgeMethodResolver：判断是否是桥梁方法 把桥梁方法转化为正常方法CollectionFactory：使用Map.class、List.class等常用集合类型生产对象Map List等集合对象Constants：加载类中的public static final常量进行分析其信息 查找 转换等Conventions：根据方法返回值 、 字段、返回相应的字符串类型名称，可以用以自动化给其起别名ControlFlowFactory：栈轨迹信息查询 判断 类 方法 及输入值是否在栈的轨迹中MethodIntrospector：为类中相关方法注入数据或过滤、把类中的相应的代理方法转化为接口方法ResolvableType：统一所有类型为ResolvableType对象来操作类型，很赞，使用很方便 2.2.2、解析类元数据类中的元数据包含了类元数据、方法元数据及注解元数据；spring使用了两种方式来注入元数据获得类、注解、方法元数据信息：1）使用ASM方式，通过加载class资源读取到相应的访问器里，来填充相应的元数据，比反射速度快很多2）使用标准的反射，从Class对象获取类、方法、字段、注解等信息注入到元数据中 2.2.3.底层Resource资源描述及基本资源加载器实现2.2.4.Property管理2.2.5.类型转换服务2.2.6.spring环境搭建2.2 spring-beans包含访问配置文件、创建和管理 bean 以及进行 Inversion of Control / Dependency Injection（IOC/DI） 操作相关的所有类。 BeanFactory：用于管理Bean的一个工厂类，获取spring bean容器的根接口 FactoryBean：它是实现了FactoryBean&lt;T&gt;接口的Bean，根据该Bean的Id从BeanFactory中获取的实际上是FactoryBean的getObject()返回的对象，而不是FactoryBean本身， 如果要获取FactoryBean对象，可以在id前面加一个&amp;符号来获取。 2.3 spring-contextspring-context模块构架与spring-core和spring-beans模块之上，提供了一个框架式的对象访问方式，是访问定义和配置的任意对象的媒介。它扩展了BeanFactory，为其增加了Bean生命周期控制、框架事件体系以及资源加载透明化等功能。 ApplicationContext是该模块的核心接口，它是BeanFactory的子类，与BeanFactory不同的是ApplicationContext容器实例化后会自动对所有的单实例Bean进行实例化与依赖关系的装配，使之处于待用状态。 2.4 spring-aop由spring-aop、spring-aspects和 spring-instrument 3个模块组成。 2.4.1 spring-aopspring-aop 是spring的另一个核心模块，提供了一个符合AOP要求的面相切面的编程实现。作为继OOP之后，对程序员影响最大的编程思想之一，AOP极大的开拓了人们对于编程的思路。 在spring中，以JDK动态代理的技术为基础，设计出了一系列的AOP横切实现，比如：前置通知、返回通知和异常通知等。同时使用 Pointcut 接口匹配切入点，可以使用现有的切入点设计横切面；也可以扩展相关方法根据需求进行切入，将代码按照功能进行分离，以便干净的解耦。 2.4.2 spring-aspects提供了与AspectJ的集成功能，主要是为AOP提供了多种实现方法。 2.4.3 spring-instrument该模块是spring-aop的一个支援模块，提供了类植入(Instrumentation)支持和类加载器的实现。主要作用于JVM启动时，生成一个代理类，程序员通过代理类在运行时修改类的字节，从而改变一个类的功能，实现AOP的功能。 2.5 spring-jcl2.6 数据访问与集成(Data Access/Integration)由spring-jdbc、spring-orm、spring-oxm、spring-jms和spring-tx组成。 2.6.1 spring-jdbcspring-jdbc模块是spring提供的JDBC抽象层，消除了繁琐的编码以及数据库厂商特有的错误代码解析。用于简化JDBC，主要提供JDBC的模板方法、关系数据库对象化方式、事务管理来简化JDBC编程，主要实现类有JdbcTemplate、SimpleJdbcTemplate以及NamedParameterJdbcTemplate。 2.6.2 spring-ormspring-orm模块是ORM的支持模块，主要集成Hibernate、Java Persistence API(JPA)和Java Data Object(JDO)用于资源管理、数据访问对象（DAO）的实现和事务策略。 2.6.3 spring-oxmspring-oxm模块主要提供一个抽象层支撑OXM(Object-to-XML-Mapping)，例如：JAXB、Castor、XMLBeans、JiBX和XStream等。 2.6.4 spring-jmsspring-jms模块（Java Message Service）为Java消息传递服务，能够发送和接收信息，自Spring Framework 4.1 以后，它还提供了对spring-messaging模块的继承。 2.6.5 spring-txspring-tx 模块是spring-jdbc事务控制实现模块，支持用于实现所有接口和所有POJO类的编程和声明式事务的管理 2.7 Web由spring-websocket、spring-webmvc、spring-web和spring-webflux组成 2.7.1 spring-webspring-web模块为spring提供了最基础的web支持，主要建立在核心容器之上，通过Servlet或者Listeners来初始化IOC容器以及Web应用上下文，自动装载WebApplicationContext，也包含一些与web相关的支持，如：Struts集成类、文件上传支持的类、FIlter类和大量辅助工具类。 2.7.2 spring-webmvc也称web-servlet模块，包含用于Web应用程序的Spring MVC和REST Web Service实现。Spring MVC框架提供了领域模型代码和Web表单之间的清晰分离，并与Spring Framework的所有其他功能集成。 2.7.3 spring-websocketSpring4.0以后新增的模块，实现双工异步通讯协议，实现了WebSocket和SocketJS，提供Socket通信和Web端的推送功能。 2.7.3 spring-webflux是一个新的非堵塞函数式Reactive Web框架，可以用来建立异步的，非阻塞，事件驱动的服务，并且扩展性非常好。 三、Ioc3.1 核心概念Spring 通过一个配置文件描述 Bean 及 Bean 之间的依赖关系，利用 Java 语言的反射功能实例化 Bean并建立 Bean 之间的依赖关系。 Spring 的 IoC 容器在完成这些底层工作的基础上，还提供了 Bean 实例缓存、生命周期管理、 Bean 实例代理、事件发布、资源装载等高级服务 3.2 核心容器类BeanFactory 是 Spring 框架的基础设施，面向 Spring 本身；ApplicationContext 面向使用 Spring 框架的开发者，几乎所有的应用场合我们都直接使用 ApplicationContext 而非底层的 BeanFactory。 3.2.1 BeanFactory BeanDefinitionRegistry注册表 :Spring 配置文件中每一个节点元素在 Spring 容器里都通过一个 BeanDefinition 对象表示，它描述了 Bean 的配置信息。而 BeanDefinitionRegistry 接口提供了向容器手工注册 BeanDefinition 对象的方法 BeanFactory 顶层接口 位于类结构树的顶端 ，它最主要的方法就是 getBean(String beanName)，该方法从容器中返回特定名称的 Bean，BeanFactory 的功能通过其他的接口得到不断扩展 ListableBeanFactory 该接口定义了访问容器中 Bean 基本信息的若干方法，如查看 Bean 的个数、获取某一类型 Bean的配置名、查看容器中是否包括某一 Bean 等方法； HierarchicalBeanFactory父子级联 :父子级联 IoC 容器的接口，子容器可以通过接口方法访问父容器； 通过HierarchicalBeanFactory 接口， Spring 的 IoC 容器可以建立父子层级关联的容器体系，子容器可以访问父容器中的 Bean，但父容器不能访问子容器的 Bean。Spring 使用父子容器实现了很多功能，比如在Spring MVC 中，展现层 Bean 位于一个子容器中，而业务层和持久层的 Bean 位于父容器中。这样，展现层 Bean 就可以引用业务层和持久层的 Bean，而业务层和持久层的 Bean 则看不到展现层的 Bean。 ConfigurableBeanFactory 增强了 IoC 容器的可定制性，它定义了设置类装载器、属性编辑器、容器初始化后置处理器等方法； AutowireCapableBeanFactory 定义了将容器中的 Bean 按某种规则（如按名字匹配、按类型匹配等）进行自动装配的方法； SingletonBeanRegistry 定义了允许在运行期间向容器注册单实例 Bean 的方法；对于单实例（ singleton）的 Bean 来说，BeanFactory 会缓存 Bean 实例，所以第二次使用 getBean() 获取 Bean 时将直接从 IoC 容器的缓存中获取 Bean 实例。Spring 在 DefaultSingletonBeanRegistry 类中提供了一个用于缓存单实例 Bean 的缓存器，它是一个用 HashMap 实现的缓存器，单实例的 Bean 以 beanName 为键保存在这个 HashMap 中。 3.2.2 ApplicationContextApplicationContext 由 BeanFactory 派 生 而 来 ， 提 供 了 更 多 面 向 实 际 应 用 的 功 能 。ApplicationContext 继承了 HierarchicalBeanFactory 和 ListableBeanFactory 接口，在此基础上，还通过多个其他的接口扩展了 BeanFactory 的功能： ClassPathXmlApplicationContext：默认从类路径加载配置文件 FileSystemXmlApplicationContext：默认从文件系统中装载配置文件 ApplicationEventPublisher：让容器拥有发布应用上下文事件的功能，包括容器启动事件、关闭事件等。 MessageSource：为应用提供 i18n 国际化消息访问的功能； ResourcePatternResolver ： 所 有 ApplicationContext 实现类都实现了类似于PathMatchingResourcePatternResolver 的功能，可以通过带前缀的 Ant 风格的资源文件路径装载 Spring 的配置文件。 LifeCycle：该接口是 Spring 2.0 加入的，该接口提供了 start()和 stop()两个方法，主要用于控制异步处理过程。在具体使用时，该接口同时被 ApplicationContext 实现及具体 Bean 实现，ApplicationContext 会将 start/stop 的信息传递给容器中所有实现了该接口的 Bean，以达到管理和控制 JMX、任务调度等目的。 ConfigurableApplicationContext 扩展于 ApplicationContext，它新增加了两个主要的方法：refresh()和 close()，让 ApplicationContext 具有启动、刷新和关闭应用上下文的能力。在应用上下文关闭的情况下调用 refresh()即可启动应用上下文，在已经启动的状态下，调用 refresh()则清除缓存并重新装载配置信息，而调用 close()则可关闭应用上下文。 3.2.3 WebApplicationContextWebApplicationContext 是专门为 Web 应用准备的，它允许从相对于 Web 根目录的路径中装载配置文件完成初始化工作。从 WebApplicationContext 中可以获得 ServletContext 的引用，整个 Web 应用上下文对象将作为属性放置到 ServletContext 中，以便 Web 应用环境可以访问 Spring 应用上下文 。 3.2.4 BeanFactory和FactoryBean的区别 「BeanFactory 是 IOC 容器」，是用来承载对象的 「FactoryBean 是一个接口」，为 Bean 提供了更加灵活的方式，通过代理一个Bean对象，对方法前后做一些操作。 3.3 Spring Bean 作用域3.3.1 Singleton单例模式，Spring IoC 容器中只会存在一个共享的 Bean 实例，无论有多少个 Bean 引用它，始终指向同一对象。该模式在多线程下是不安全的。Singleton 作用域是 Spring 中的缺省作用域 ，也是最常见的作用域。 3.3.2 Prototype原型模式，每次通过 Spring 容器获取 prototype 定义的 bean 时，容器都将创建一个新的 Bean 实例，每个 Bean 实例都有自己的属性和状态，而 singleton 全局只有一个对象。根据经验，对有状态的bean使用prototype作用域，而对无状态的bean使用singleton 作用域。 3.3.3 Request在一次 Http 请求中，容器会返回该 Bean 的同一实例。而对不同的 Http 请求则会产生新的 Bean，而且该 bean 仅在当前 Http Request 内有效,当前 Http 请求结束，该 bean 实例也将会被销毁。 3.3.4 Session在一次 Http Session 中，容器会返回该 Bean 的同一实例。而对不同的 Session 请求则会创建新的实例，该 bean 实例仅在当前 Session 内有效。同 Http 请求相同，每一次 session 请求创建新的实例，而不同的实例之间不共享属性，且实例仅在自己的 session 请求内有效，请求结束，则实例将被销毁。 3.3.5 Global Session在一个全局的 Http Session 中，容器会返回该 Bean 的同一个实例，仅在使用portlet context 时有效。 3.4 Spring Bean 生命周期该流程建议反复查看[时序图](https://www.processon.com/view/605833d9e0b34d780ef6440a)来进行理解，这段我每次理解起来感觉都很吃力，中间还穿插了Spring 的循环依赖问题。总的来说可以分为四个阶段来分析，实例化和初始化阶段还分别配有相对应的钩子接口进行一些增强处理。 3.4.1 实例化阶段InstantiationAwareBeanPostProcessor接口的postProcessBeforeInstantiation和postProcessAfterInstantiation方法，分别作为实例化中间的前置和后置方法，他是Spring提供的钩子，可以供Bean在实例化前后使用。 3.4.2 属性赋值调用了PopulateBean方法，里面会根据Autowire的方式ByType还是ByName来决定填充Bean的方式来进行属性填充 3.4.3 初始化 Aware接口的依赖注入 BeanPostProcessor 在初始化前后的处理 以及InitializingBean（会根据判断当前bean有无继成关系来判断调用反射的哪个具体方法来进行bean的实例化）的初始化操作 3.4.4 销毁 Destructionbean 标签有两个重要的属性（init-method 和 destroy-method）。用它们你可以自己定制初始化和注销方法。它们也有相应的注解（@PostConstruct 和@PreDestroy） 3.5 Spring 依赖注入的方式3.5.1 构造器注入Spring容器先创建单例A，A依赖B，然后将A放在“当前创建Bean池”中，此时创建B,B依赖C ,然后将B放在“当前创建Bean池”中,此时创建C，C又依赖A， 但是，此时A已经在池中，所以会报错，，因为在池中的Bean都是未初始化完的，所以会依赖错误 ， Spring容器会将每一个正在创建的Bean 标识符放在一个“当前创建Bean池”中，Bean标识符在创建过程中将一直保持在这个池中，因此如果在创建Bean过程中发现自己已经在“当前创建Bean池”里时将抛出BeanCurrentlyInCreationException异常表示循环依赖；而对于创建完毕的Bean将从“当前创建Bean池”中清除掉。 3.5.2 Setter方式3.5.2.1 单例(Singleton)可以解决循环依赖 Spring容器会将每一个正在创建的Bean 标识符放在一个“当前创建Bean池”中，Bean标识符在创建过程中将一直保持在这个池中，因此如果在创建Bean过程中发现自己已经在“当前创建Bean池”里时将抛出BeanCurrentlyInCreationException异常表示循环依赖；而对于创建完毕的Bean将从“当前创建Bean池”中清除掉。 3.5.2.2 原型(Prototype)无法解决循环依赖 3.5.3 Field注入（基于注解的方式进行依赖注入）通过Autowired来进行属性注入 3.5.3.1 单例(Singleton)3.5.3.2 原型(Prototype)3.5.4 构造器注入和Setter方法注入的区别两种依赖方式都可以使用，构造器注入和Setter方法注入。最好的解决方案是用构造器参数实现强制依赖，setter方法实现可选依赖。 构造函数注入 setter注 入 没有部分注入 有部分注入 不会覆盖 setter 属 性 会覆盖 setter 属 性 任意修改都会创建一个新实例 任意修改不会创建一个新实例 适用于设置很多属性 适用于设置少量属性 3.6 Spring是如何解决循环依赖的3.6.1 解决循环依赖的方式循环依赖就是说两个对象相互依赖，形成了一个环形的调用链路 spring 使用三级缓存去解决循环依赖的，其「核心逻辑就是把实例化和初始化的步骤分开，然后放入缓存中」，供另一个对象调用 「第一级缓存」：用来保存实例化、初始化都完成的对象 「第二级缓存」：用来保存实例化完成，但是未初始化完成的对象 「第三级缓存」：用来保存一个对象工厂，提供一个匿名内部类，用于创建二级缓存中的对象 当 A、B 两个类发生循环引用时 大致流程 1.A 完成实例化后，去「创建一个对象工厂，并放入三级缓存」当中 如果 A 被 AOP 代理，那么通过这个工厂获取到的就是 A 代理后的对象 如果 A 没有被 AOP 代理，那么这个工厂获取到的就是 A 实例化的对象 2.A 进行属性注入时，去「创建 B」 3.B 进行属性注入，需要 A ，则「从三级缓存中去取 A 工厂代理对象」并注入，然后删除三级缓存中的 A 工厂，将 A 对象放入二级缓存 4.B 完成后续属性注入，直到初始化结束，将 B 放入一级缓存 5.「A 从一级缓存中取到 B 并且注入 B」, 直到完成后续操作，将 A 从二级缓存删除并且放入一级缓存，循环依赖结束 spring 解决循环依赖有两个前提条件： 1.「不全是构造器方式」的循环依赖(否则无法分离初始化和实例化的操作) 2.「必须是单例」(否则无法保证是同一对象) 3.6.2 为什么使用三级缓存，而不是二级缓存三级缓存的功能是只有真正发生循环依赖的时候，才去提前生成代理对象，否则只会「创建一个工厂并将其放入到三级缓存」中，但是不会去通过这个工厂去真正创建对象。 如果使用二级缓存解决循环依赖，意味着所有 Bean 在实例化后就要完成 AOP 代理，这样「违背了 Spring 设计的原则」，Spring 在设计之初就是在 Bean 生命周期的最后一步来完成 AOP 代理，而不是在实例化后就立马进行 AOP 代理。 3.7 Autowired和Resource注解有什么区别 「@Resource 是 Java 自己的注解」，@Resource 有两个属性是比较重要的，分是 name 和 type；Spring 将 @Resource 注解的 name 属性解析为 bean 的名字，而 type 属性则解析为 bean 的类型。所以如果使用 name 属性，则使用 byName 的自动注入策略，而使用 type 属性时则使用 byType 自动注入策略。如果既不指定 name 也不指定 type 属性，这时将通过反射机制使用 byName 自动注入策略。 「@Autowired 是spring 的注解」，是 spring2.5 版本引入的，Autowired 只根据 type 进行注入，「不会去匹配 name」。如果涉及到 type 无法辨别注入对象时，那需要依赖 @Qualifier 或 @Primary 注解一起来修饰。 四、Aop4.1 应用场景 事务管理 安全检查 权限控制 日志 错误处理 4.2 常用术语具体可以参看Spring的官方文档有关这方面的介绍，我觉得官方的概念有点晦涩难懂，尝试着翻译成人话来理解一下其中的一些核心概念，供日常使用。 首先，我搜索到了一个比较容易理解的概念图进行说明 4.2.1 连接点(Joinpoint)连接点，这是一个可以用来进行增强的方法点，说白了就是对具体哪个方法进行增强。 4.2.2 切入点(Pointcut)切入点是告诉我们在方法的什么位置进行增强，比如在方法执行之前增强，还是执行之后增强，或者两者都有。 4.2.3 AdviceAdvice表示需要增强的功能 4.2.3.1 前置通知 （Before Advice）在某连接点之前执行的通知，但这个通知不能阻止连接点之前的执行流程（除非抛出了一个异常） 4.2.3.2 后置通知 (After Returning Advice)在某连接点正常完成后执行的Advice。 4.2.3.3 异常通知 (After throwing advice)在方法抛出异常退出时执行的Adivce 4.2.3.4 最终通知 (After (finally) advice)当某连接点退出的时候执行的Advice，不论是正常结束流程还是异常退出 4.2.3.5 环绕通知(Around advice)包围一个连接点的Advice,这是最强大的一种通知类型。环绕通知可以在方法调用前后完成自定义的行为。它也会选择是否继续执行连接点或者直接返回返回值或者抛出异常来结束执行。 4.3 Spring Aop 和 AspectJSpring 依然采用运行时生成动态代理的方式来增强目标对象，所以它不需要增加额外的编译，也不需要 AspectJ 的织入器支持；而 AspectJ 在采用编译时增强，所以 AspectJ 需要使用自己的编译器来编译 Java 文件，还需要织入器。 4.3 实现方式4.3.1 JDK动态代理使用的是Jdk原生的动态代理技术，只能代理接口，而不能代理实际使用的类。Jdk实现的动态代理，具体实现是基于Reflect包中的Proxy和InvocationHandler两个接口去实现的。 4.3.2 CGLib动态代理4.3.2.1 使用示例被代理类： 12345678910111213141516/** * @author: Yaowx * @email worthyyao@qq.com * @Date: 2021/11/26 */public class Hello &#123; public static void main(String[] args) &#123; new Hello().sayHello(); &#125; public void sayHello()&#123; System.out.println("hello world"); &#125;&#125; 实际代理类： 123456789101112131415161718192021222324252627282930import org.springframework.cglib.proxy.Enhancer;import org.springframework.cglib.proxy.MethodInterceptor;import org.springframework.cglib.proxy.MethodProxy;import java.lang.reflect.Method;/** * @author: Yaowx * @email worthyyao@qq.com * @Date: 2021/11/26 */public class MyInterceptor implements MethodInterceptor &#123; public static void main(String[] args) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(Hello.class); enhancer.setCallback(new MyInterceptor()); Hello hello = (Hello) enhancer.create(); hello.sayHello(); &#125; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println("开始打招呼前"); Object result=methodProxy.invokeSuper(o,objects); System.out.println("开始打招呼后"); return result; &#125;&#125; 4.3.2.2 原理说明CGLIB是通过字节码增强处理框架 ASM，来生成字节码并装载到JVM。和JDK代理基于接口实现方式不同的是，CGLIB没有局限于接口，采用的是生成子类的方式。这个子类本质上就是一个Class 对象，换句话说原来是执行原有的Class，CGLIB会通过字节码增强的方式，在字节码的层面生成一个子类去集成需要增强的类，在子类中加入需要增强的方法，让这个子类代替原有的类，完成增强的操作。 CGLIB生成Class对象分为三个步骤： 生成指定类的Class对象字节数组。 将Class对象字节数组转换为Class对象。 通过 Class.forName 方法将Class对象装载到JVM。 4.3.3 区别JDK 动态代理时业务类「必须要实现某个接口」，它是「基于反射的机制实现的」，生成一个实现同样接口的一个代理类，然后通过重写方法的方式，实现对代码的增强。 CGLIB 动态代理是使用字节码处理框架 ASM，其原理是通过字节码技术为一个类「创建子类，然后重写父类的方法」，实现对代码的增强。 五、常见问题5.1 循环依赖问题5.2 Bean线程安全问题5.3 BeanFactory和FactoryBean的区别六、Spring事务6.1 数据库事务的隔离级别 隔离级别 效果 读未提交 会产生数据脏读 读已提交 能解决数据脏读，没有提交的事物数据不会读取到，但在同一个事物中，可能会产生多次读取的数据不一致的问题，又称为不可重复读的问题 可重复读 能解决脏读、不可重复读的问题。但是对于幻读问题，对于Mysql而言，Mysql是通过了引入了Next-lock算法来解决的该问题，说人话就是基于行级锁和间隙锁的组合来解决这个问题的 串行化 虽说能解决各种读的问题，但是串行化后只能同时使用一个线程，排队场景对于实际生产使用来说，毫无意义 6.2 Spring 对事务的支持6.2.1 Spring事务分类 编程式事务 声明式事务（通过Transaction注解来使用，目前使用较多） 6.2.2 Spring事务的传播机制事务传播特性就是，事务中嵌套其他的事务，事务与被嵌套事务之间如何相互影响，如何执行的，这就是事务传播性。 1234567891011121314151617181920212223242526272829303132333435import org.springframework.beans.factory.annotation.Autowired;import org.springframework.transaction.annotation.Transactional;import org.springframework.transaction.annotation.Propagation;/** * @author: Yaowx * @email worthyyao@qq.com * @Date: 2021/11/26 */public class ServiceA &#123; @Autowired private ServiceB serviceB; @Transactional public void methodA()&#123; try &#123; serviceB.methodB(); &#125;catch (Exception e)&#123; System.out.println("method b 发生异常操作"); &#125; &#125;&#125;public class ServiceB &#123; @Transactional(propagation = Propagation.REQUIRES_NEW) public void methodB() throws Exception &#123; System.out.println("做service b的数据库操作"); &#125;&#125; 存在上述嵌套事务的情况那么如何描述两个方法的事务行为的互相作用和互相影响呢，这里将事务传播行为分为了7种，主要集中在被嵌套的方法methodB这端的定义，也就是@Transcational(propagation = PROPAGATION_REQUIRES_NEW) ,这句定义中propagation的赋值： PROPAGATION_REQUIRED：这个是最常见的，就是说，如果ServiceA.methodA调用了ServiceB.methodB，如果ServiceA.methodA开启了事务，然后ServiceB.methodB也声明了事务，那么ServiceB.methodB不会开启独立事务，而是将自己的操作放在ServiceA.methodA的事务中来执行，ServiceA.methodA和ServiceB.methodB任何一个报错都会导致整个事务回滚。 PROPAGATION_SUPPORTS：如果ServiceA.methodA开了事务，那么ServiceB.methodB就将自己加入ServiceA.methodA中来运行，如果ServiceA.methodA没有开事务，那么ServiceB.methodB自己也不开事务 PROPAGATION_MANDATORY：必须被一个开启了事务的方法来调用自己，否则报错。 PROPAGATION_REQUIRES_NEW：ServiceB.method强制性自己开启一个新的事务，然后ServiceA.methodA的事务会等待ServiceB.methodB事务完了再继续执行。这就是影响的回滚了，如果ServiceA.methodA报错了，ServiceB.methodB是不会受到影响的，ServiceB.methodB报错了，ServiceA.methodA也可以选择性的回滚或者是提交。 PROPAGATION_NOT_SUPPORTED：就是ServiceB.methodB不支持事务，ServiceA.methodA的事务执行到ServiceB.methodB那儿，就挂起来了，ServiceB.methodB用非事务方式运行结束，ServiceA.methodA事务再继续运行。这个好处就是ServiceB.methodB代码报错不会让ServiceA.methodA回滚。 PROPAGATION_NEVER：不能被一个事务来调用，ServiceA.methodA开事务了，但是调用了ServiceB.methodB会报错。 PROPAGATION_NESTED：开启嵌套事务，ServiceB.methodB开启一个子事务，如果回滚的话，那么ServiceB.methodB就回滚到开启子事务的这个save point。 6.2.3 Spring事务失效的场景和原理6.2.3.1 失效场景 没有被Spring管理的方法：没有被Spring管理的Bean，如果其中出现了方法需要进行事务处理的情况，此时的事务不会执行 方法不是public：@Transactional 只能用于 public 的方法上，否则事务不会失效，如果要用在非 public 方法上 方法被final修饰 自身调用问题：当一个Service中存在多个方法，都标注了事务@Transactional，当其中一个方法调用另外一个方法的时候，被调用方法中的事务是不会执行的。 数据源没有配置事务管理器：Datasource没有配置事务，当然不会生效 事务传播级别选择：选择了错误的传播级别，会导致事物无法生效 事务中出现异常：如果在执行的方法中执行的事务，由于异常退出的情况，那么这个事务是无法完成的。(异常没有抛出的情况下) 错误定义异常类型：在事务中出现异常的时候，需要对异常进行定义才能正确执行事务。如果出现错误的定义，当出现事务中的异常时，还可以继续执行事务。 6.2.3.2 原理为什么失效，这些场景都和Aop的原理有着很大的关系，因为Spring的事务使用了Aop机制，而无论是使用Cglib还是Jdk动态代理，都有一个特点，接口和子类都是无法实现private或者final方法的，所以如果出现这些场景，会导致Spring 的事务无法生效。 6.2.4 Spring事务原理基于Aop机制去实现的， 七、设计模式7.1 工厂模式通过BeanFactory和ApplicationContext来生产Bean对象 7.2 单例模式Spring中的Bean默认都是单例 7.3 模版模式父类定义了骨架（调用哪些方法及顺序），某些特定方法由子类实现。 最大的好处：代码复用，减少重复代码。除了子类要实现的特定方法，其他方法及方法调用顺序都在父类中预先写好了。 所以父类模板方法中有两类方法： 共同的方法：所有子类都会用到的代码 不同的方法：子类要覆盖的方法，分为两种： 抽象方法：父类中的是抽象方法，子类必须覆盖 钩子方法：父类中是一个空方法，子类继承了默认也是空的 注：为什么叫钩子，子类可以通过这个钩子（方法），控制父类，因为这个钩子实际是父类的方法（空方法）！ 7.4 责任链模式7.5 观察者模式7.6 代理模式7.7 装饰器模式7.8 适配器模式7.9 策略模式​ 举例：Spring框架的资源访问Resource接口。该接口提供了更强的资源访问能力，Spring 框架本身大量使用了 Resource 接口来访问底层资源。 Resource 接口介绍​ Rsource 接口是具体资源访问策略的抽象，也是所有资源访问类所实现的接口。 ​ Resource 接口主要提供了如下几个方法: getInputStream()：定位并打开资源，返回资源对应的输入流。每次调用都返回新的输入流。调用者必须负责关闭输入流。 exists()：返回 Resource 所指向的资源是否存在。 isOpen()：返回资源文件是否打开，如果资源文件不能多次读取，每次读取结束应该显式关闭，以防止资源泄漏。 getDescription()：返回资源的描述信息，通常用于资源处理出错时输出该信息，通常是全限定文件名或实际 URL。 getFile：返回资源对应的 File 对象。 getURL：返回资源对应的 URL 对象。 最后两个方法通常无须使用，仅在通过简单方式访问无法实现时，Resource 提供传统的资源访问的功能。 Resource 接口本身没有提供访问任何底层资源的实现逻辑，针对不同的底层资源，Spring 将会提供不同的 Resource 实现类，不同的实现类负责不同的资源访问逻辑。Spring 为 Resource 接口提供了如下实现类： UrlResource：访问网络资源的实现类。 ClassPathResource：访问类加载路径里资源的实现类。 FileSystemResource：访问文件系统里资源的实现类。 ServletContextResource：访问相对于 ServletContext 路径里的资源的实现类. InputStreamResource：访问输入流资源的实现类。 ByteArrayResource：访问字节数组资源的实现类。 这些 Resource 实现类，针对不同的的底层资源，提供了相应的资源访问逻辑，并提供便捷的包装，以利于客户端程序的资源访问。 八、Spring MVC8.1 Servlet 生命周期 实例化 初始化 执行处理 销毁 8.2 Filter和Interceptor有什么区别，使用场景有什么不同九、Spring BootSpring Boot 有好几个功能和特性，但是最主要，也最常见(最常问)的是自动配置的特性。这里可以主要分析一下该功能点的实现原理，以及如何实现一个自己的 spring boot starter功能。这块详细可以参照 官方的reference，我觉得写的非常好。 9.1 什么是 Spring Boot 的自动装配9.1.1 Spi机制SPI是Service Provider Interface的缩写，这种技术用人话来理解，就是官方定义一套规范，由各个厂商、个人根据官方定义的Service接口，自行实现具体的技术细节。而Spi技术，则通过该机制为某个接口寻找相对应的服务。在Java的世界中，最常见的使用该技术的案例有： Jdbc连接 Dubbo Spring Boot 的自动依赖 9.1.2 Spring Boot 的自动装配Spring Boot定义了一套接口规范，根据规定，我们在META-INF下面写的spring.factories文件会被SpringBoot扫描，并将该文件中的内容进行加载到Spring到容器中去。对于外包的Jar包，我们可以按照SpringBoot规定的标准，将自己的bean 进行自动装配，共SpringBoot调用。 9.2 SpringBoot 实现自动装配的原理9.2.1 SpringBoot的核心注解如果去看官网，会发现官方的Reference里面会强调一个核心注解SpringBootApplication，这个注解其实是一个组合注解，当你使用这个注解的时候，标明了他同时集成了如下三个注解： SpringBootConfiguration：这是Configuration类的子集，标明这是一个config类，可以被注入进去 EnableAutoConfiguration：开启自动注入功能，该注解如果加上了，表明了项目是打开了自动注入的功能等 ComponentScan：组件扫描功能，该注解加上，表明会将所有的configuration类扫描并装配成Spring的bean 对于自动装配功能来说，他就是EnableAutoConfiguration注解起的作用。下面详细说一下这个注解所起到的功能。 9.2.2 EnableAutoConfiguration 注解的作用这个注解其实也没有特别的黑魔法，主要还是一层层的嵌套调用的。如果说核心代码和思路的话，我觉得可以重点可以看这一段 123456789101112131415161718protected AutoConfigurationEntry getAutoConfigurationEntry(AnnotationMetadata annotationMetadata) &#123; //1、判断有没有开启自动注入功能 if (!isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; AnnotationAttributes attributes = getAttributes(annotationMetadata); //2、获取需要进行自动装配的配置类 主要做的事情就是去读这个META-INF/spring.factories里面的自动配置类，全都读取出来 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); configurations = removeDuplicates(configurations); Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); //3、对获取到的自动配置的类进行排除，排除的逻辑是根据conditional注解来确定的，所有不符合条件的自动配置类实际上并不会真正进入装配bean的环节的，具体conditional怎么使用，下面具体介绍 configurations = getConfigurationClassFilter().filter(configurations); fireAutoConfigurationImportEvents(configurations, exclusions); //4、等这个方法结束的时候，其实就可以返回真正需要进行自动装配的autoconfiguration类了。 return new AutoConfigurationEntry(configurations, exclusions);&#125; 9.2.3 Conditional注解的使用官方Reference还是强推，写的也很详细，conditional注解还细分如下几种： Class Conditions Bean Conditions Property Conditions Resource Conditions WebApplication Conditions SpEl Conditions Spring spel表达式类condition 具体使用的时候，经常可以看见如下图这样的autoconfiguration，我随机打开了RedisAutoConfiguration来进行解释。 在这个图片里面，由于我没有引入spring-boot-data-redis的相关依赖，导致相关类是红色的。而conditionalOnClass类的作用是什么呢？他表明只有类路径下有相关类导入时，才会加载相关类。而conditionalOnSingleCandidate表明只有一个唯一存在的单例类时，该bean才会被装配。 更多的condition的用法可以翻阅官方Api，其实还是蛮好理解的。还有一些诸如存在相关配置文件才会加载类的行为。 9.3 Spring Boot 其他特性其实Spring Boot还有不少其他特性，诸如Spring Boot actuator(用于监控Spring boot应用)，Spring Cli（命令行程序，实际使用比较少）。]]></content>
  </entry>
  <entry>
    <title><![CDATA[es quick start]]></title>
    <url>%2F2021%2F04%2F16%2Fes-quick-start%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring 笔记之装配]]></title>
    <url>%2F2017%2F11%2F01%2FSpring%20%E7%AC%94%E8%AE%B0%E4%B9%8B%E8%A3%85%E9%85%8D%2F</url>
    <content type="text"><![CDATA[概述​ 这几天断断续续的在看Spring实战，主要看了前两章的东西，特此记录一下。 依赖注入​ 作为Spring最为核心的概念，依赖注入(Dependency Injection,DI)这个名词既绕口，也没那么好理解。他其实是一种软件工程设计原则控制反转(Inversion of Control,IoC)的一种实现。 究其目的，是为了能够减少面向对象软件工程中多对象之间耦合度太高的问题。具体到Spring框架来说，在Spring的世界观里面，对象之间的创建与调用都应该由Spring的IoC容器来负责，而不应该由对象之间相互调用，这种设计思想，可以能够很好的减少对象之间的相互耦合。而在Spring中如何自动的创建对象实例bean呢，这种行为在Spring中的名词就是装配(Wiring)。随着框架的完善，今天的Spring主要以三种方式来完成对Java Bean的装配。 装配方式自动装配​ Spring发展到如今，自动化的程度很高，自动装配也是非常方便并且在Spring Boot框架中大量使用。在Spring实战这本书中,也属于重点介绍的技术，Spring技术主要通过两个角度来实现自动化的装配： 组件扫描(component scanning):Spring自动发现应用上下文中(ApplicationContext)所创建的bean 自动装配(autowiring): Spring自动的满足bean之间的相互依赖 ​ 举个例子可以很清楚的看见Spring是如何通过自动装配的方式来完成自动的装配。假设以Spring Boot框架为例，有一个Singer去演唱一首歌，那么当他需要唱歌时需要哪些东西呢，在Spring的自动装配中，比较简单。首先需要定义能够唱歌的灵魂歌手LeiJun： 1234567@Componentpublic class LeiJun implements Singer &#123; @Override public void sing() &#123; System.out.println("Are you ok?"); &#125;&#125; 光有人是不够的，如何能够唱歌呢，注入进来就好了! 12345678910@RunWith(SpringRunner.class)@ContextConfiguration(classes = DemoApplication.class)public class DemoApplicationTests &#123; @Autowired private LeiJun leiJun; @Test public void test()&#123; leiJun.sing(); &#125;&#125; 在Spring中，利用自动装配去使用一个对象就这么简单，依靠@Component注解与@Autowired注解就能够完成对一个对象的使用，但其实在这背后，Spring默默的为我们做了很多的事情。首先，当为一个对象定义为@Component注解时，相当于对Spring声明了这个类将会作为组件类，并且告知Spring要为这个类创建bean，当然，组件的扫描并不是直接启动的，需要通过对Spring的配置从而启动对所有@Component的注解的扫描，并创建相应的bean，以Spring Boot为例，在其启动时会有一个@SpringBootApplication注解，这其实是个多重注解的组合， 123456789101112@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; ...&#125; 其中，ComponentScan的作用尤为重要，在项目启动的时候，该注解会去扫描根据配置好的Package下的类，在本例中，他就会将加载了@Component注解的LeiJun加载入Ioc容器中并自动为其创建一个bean，而如单元测试中例子所示，当在Spring框架中需要引用一个bean时，通过@Autowired将其从IoC容器中注入进来就可以使用了。 ​ 以上，就是通过自动装配的姿势，让LeiJun唱歌的过程。 JavaConfig装配并不是任何时候自动配置都是合适的场景，这种时候 ，总需要去执行Plan B，此时，可能就需要我们对JavaBean进行的显示的配置了，JavaConfig的装配方式比较特殊，因为他就是Java代码，就像程序中的其他代码一样，只不过不包含任何业务逻辑，显得比较独立。再以一位歌手为例，就能清楚JavaConfig的配置方式。首先，都需要定义一位歌手: 123456public class GongLinNa implements Singer&#123; @Override public void sing() &#123; System.out.println("法海你不懂爱"); &#125;&#125; 相比较上次而言，这位歌手并没有一个Component注解,这是因为她没有选择通过自动装配的方式注入进IoC容器的缘故，通过JavaConfig，可以达到同样的目的! 1234567@Configurationpublic class SingerConfig &#123; @Bean public Singer gongLinNa()&#123; return new GongLinNa(); &#125;&#125; 同样也可以唱歌: 12345678910@RunWith(SpringRunner.class)@ContextConfiguration(classes = DemoApplication.class)public class DemoApplicationTests &#123; @Autowired private Singer gongLinNa; @Test public void test002()&#123; gongLinNa.sing(); &#125;&#125; 如方式一相比，能够明显的观察出不同，少了一个@Component注解，多了一个SingerConifg类。这个类中，多了两个注解@Configuration和@Bean。其实从名字就能够看出，Configuration表明应用了这个注解的Java类就是一个Java配置类，而@Bean则表明了这个方法将为Spring返回一个Bean，通过这种方式，Spring同样能够将其注入进来，并在其他的地方注入使用。相比较与自动注入而言，这种要稍微繁琐一点。使用场景，以Spring Boot为例，Spring Boot 各种起步starter中的很多基础包都是以这种方式配置，并且通过EnableAutoConfiguration将符合条件的配置加载到容器中来并且使用。 XML方式xml方式的配置方式，在Spring中，有着悠久的历史。简而言之，类似与JavaConfig方式，只不过这种bean的方式并不是通过Java代码，而是xml的方式进行约定。由于其历史的悠久性，注定了其繁琐程度也要大大高于另外两种方式，在如今的项目工程中，实际使用的也并不多。通常情况下，自动装配和JavaConfig就已经足够使用了。 常用注解Spring并不会通过强制约定项目代码去实现一个Spring规范的接口或者集成Spring规范的类，通常来说，当需要使用起Spring的特性，注解是必不可少的，在进行依赖注入的使用过程中，以下的几个注解是我能够经常看到的。 @Component： 这个简单的注解通常注解在类上，表明这个类是Spring的一个组件，而Spring看到这样的类，当配置了自动扫描时，将会自动将其收集到容器中并为其创建bean。 @Service @Controller @Repository : 虽然Component注解非常好用，但在实际的应用过程中，这三个注解其实是更常用的。以@Service为例: 1234567@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Service &#123; String value() default "";&#125; 可以发现，它上面也有一个@Component注解，为什么要使用他们而不是直接使用@Component呢，其实只是为了表意更清楚而已，Service表明这是一个Service层的对象，Controller表明这是一个控制层组件，而Repository则表明这是一个与数据访问相关的组件。 @ComponentScan: 自动扫描注解，这个注解通常配置在Spring应用启动时，当启动应用时，ComponentScan注解就可以去搜集所有已经声明了的组件并将它们组装入容器中。 @Autowired: 当Bean已经在容器时,一个Atuowired即可注入到当前类中并进行使用. @Configuration: 标注在类上,表明这是一个JavaConfiguration类. @Bean 标注于方法上面,表面将返回一个JavaBean.]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>依赖注入</tag>
        <tag>装配</tag>
        <tag>注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017年的8月小结]]></title>
    <url>%2F2017%2F08%2F31%2F2017%E5%B9%B4%E7%9A%848%E6%9C%88%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[毕业彻底的从学校走向社会，已经有两个月了。慢慢的，已经可以适应如今的工作节奏了。相较于学校中比较宽松的氛围，公司是另外一种Style。但也还好，push的并不是很紧，也是因为自己的任务并不是核心的原因吧，组内的压力还没有来到我的身上。越来越觉得，作为一名程序员，一定的文字输出能力也是很有必要的。在今后的时光里，也希望自己经常能够记录下自己成长的轨迹。 技术这两个月的时间，还没有接触到特别核心的任务，不过这些奇奇怪怪的小任务也让我对Java有了更多的了解。主要来说，对Log4j的日志分流，对在不同系统中读取网络设备IP地址，以及Gradle项目的构建过程以及Groovy的学习是我最近两个月所学习到的东西。组内大神的带领下，学习这些东西的过程中感觉是有趣的，有时候，身处其中的解决一个问题又出现另一个问题的感觉也会让我产生出一定的挫败感，但更多时候，搞清楚一个东西也是蛮有意思的事情。不过这么多时间来，我都没有将这些知识点总结过，今天看20天前写的代码时，已经有点生疏了。另外，也一直没有读一些比较好的书籍，这一点希望后面的时间中要去改进。 生活完全工作后的周末与曾经读研的时候大不相同。其实，读研也无所谓什么假期的，而现在终于有一种可以free的感觉。我可以出去瞅瞅逛逛玩一玩了，哈哈。冰与火之歌的第七季正好也是在这段时间内追完了。相较于去年时的心境，感觉还是好很多的。另外，终于可以组装一个心心念念的台式机了。由于矿工们的爆炒，作为一名穷人只好默默的靠着CPU上的集显苟活，只希望矿难早日来到，我好收矿渣 = =。 读书本月无读书…..感觉完全聊不下去了。希望，只是希望，下次更新总结的时候，有东西可写。 转眼又是新的一月，fighting！]]></content>
  </entry>
  <entry>
    <title><![CDATA[hexo更换电脑重新部署]]></title>
    <url>%2F2016%2F11%2F07%2Fhexo%E6%9B%B4%E6%8D%A2%E7%94%B5%E8%84%91%E9%87%8D%E6%96%B0%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[电脑系统重装之后，之前的配置都丢失了，重新部署是个坑，我给重新踩一下，写下这个文档，免得下次再次踩坑。 更换淘宝源在重新安装hexo的时候，Nodejs本身的速度还好，Windows下直接在官网下载安装就可以了，不过hexo本身可能是因为墙的原因，速度真的是太卡了，还常常安装失败。后来改用了淘宝的源，速度真的是要好了很多。改成淘宝源很简单:1npm install -g cnpm --registry=https://registry.npm.taobao.org` 等这个安装完后，将涉及到npm install的都改成cnpm install就可以了。 安装hexo和npm包两条命令就可以。安装hexo:1cnpm install hexo-cli -g cd进入blog文件夹后,安装npm包:1cnpm install 使用体验而言，比国外的速度实在要快太多。 利用git pages同步服务项目的master我是放在coding.net上面，同时将hexo的_config.yml中的deploy字段设置成coding-pages,如下。1234type: gitrepository: git@git.coding.net:yaowenxi/yaowenxi.gitbranch: coding-pages 在部署新的文章的时候，我只需要先将master的分支用git add git commit git push推送上去，然后再将pages页面deploy一下就行了。deploy命令:1hexo g -d 至此，一遍文章的部署就算搞定了。]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[几种常用的排序算法总结]]></title>
    <url>%2F2016%2F10%2F02%2F%E5%87%A0%E7%A7%8D%E5%B8%B8%E7%94%A8%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[简述排序算法在各种各样的题中出现的蛮多的，不管是算法的编程题还是问时间复杂度之类的题目，虽然之前考研的时候都考过，不过那个时候自己也没有动手去实践，这么多排序算法放在一起，我也经常弄混，前两天就狠下心决定把所有的排序算法统统都实践一遍，并且记录下来，其中时间复杂度，空间复杂度和稳定性的分析我都放到注释中去了，希望以后再碰到的时候能够不要再忘记了。 插入排序插入排序是一种简单直观的排序算法，其基本思想在于每次将一个待排序的记录，按其关键字大小插入到前面已经排好序的子序列中，直到全部记录插入完成。 直接插入排序直接插入排序是一种最简单也是最直观的插入算法。其具体过程如下：假设在排序过程中，待排序表L[1…n]中，前i-1个元素都是已经排好序的时候，将第i个元素插入其中，这样循环下来，就可以让整个排序表有序。其中插入的操作可以如下: 查找出L(i)在L[1…i-1]中的插入位置k。 将L[k…i-1]中所有元素全部后移一个位置。 将L(i)复制到L(k)。 1234567891011121314151617181920/*** 算法名称:直接插入排序* 空间效率:仅使用了常数个辅助单元，因而空间复杂度为O(1)* 时间效率:在最好情况下，如果整个序列都已经是有序的，此时每插入一个都只需要比较一次而* 不用移动元素，因而时间复杂度为O(n)。而在平均情况下，时间复杂度则为O(n^2)。* 稳定性: 由于每次插入元素时总是从后向前先比较再移动，所以并不会出现相对位置发生变化* 的情况，也就是意味着直接插入排序是一个稳定的排序算法。*/public static void insertSort(int[] array)&#123; int temp,j; for(int i=1;i&lt;array.length;i++)&#123; if(array[i]&lt;array[i-1])&#123; temp=array[i]; for (j=i-1;j&gt;=0&amp;&amp;temp&lt;array[j];j--)&#123; array[j+1]=array[j]; &#125; array[j+1]=temp; &#125; &#125;&#125; 希尔排序希尔排序，又称为缩小增量排序。希尔排序的基本思想是：先将待排序表分割成若干个中间相差d的子表，然后分别进行插入排序，而当整个表中的元素已经基本有序的时候，再对全体记录进行一次直接插入排序。希尔排序的算法如下:123456789101112131415161718192021222324/*** 排序名称:希尔排序* 空间效率:仅使用了常数个辅助单元，因而空间复杂度为O(1)* 时间效率:希尔排序的时间复杂度依赖于增量序列函数，其时间复杂度是并不一定的，当* 数组长度n在一定范围内的时候，时间复杂度约为O(n^1.3)，而最坏情况下则会达到O(n^2)* 稳定性: 当相同关键字的记录被划分到不同的子表的时候，可能会改变它们之间的相对次序，所* 以希尔排序是个不稳定的排序算法*/public static void shellSort(int[] array)&#123; int i,j,k,temp; for (int gap=array.length/2;gap&gt;0;gap/=2)&#123; for (i=0;i&lt;gap;i++)&#123; for (j=i+gap;j&lt;array.length;j+=gap)&#123; if (array[j]&lt;array[j-gap])&#123; temp=array[j]; for (k=j-gap;k&gt;=0&amp;&amp;temp&lt;array[k];k-=gap)&#123; array[k+gap]=array[k]; &#125; array[k+gap]=temp; &#125; &#125; &#125; &#125;&#125; 交换排序所谓的交换，就是根据序列中两个元素关键字的比较结果来兑换这两个记录在序列中的位置。基于交换的排序算法有很多，常用的主要是冒泡排序和快速排序。其中冒泡排序比较简单，而快速排序则使用的非常的广泛，因为它在大部分的应用场景下效果都是很好的。 冒泡排序冒泡排序算法的基本思想是：假设待排序表长为n，从后往前两两比较相邻元素的值，如果是逆序，就可以将他们进行交换，这样序列比较完一次就可以称之为一趟冒泡，结果将最小的元素交换到待排序列的第一个位置，而在下一趟排序的时候，前一趟已经确定的元素就不会继续进行排序。这样通过n-1趟就能将整个序列变得有序。123456789101112131415161718/*** 排序名称:冒泡排序* 空间效率:仅使用了常数个辅助单元，因而空间复杂度为O(1)* 时间效率: 当进行n-1趟比较，并且每一趟都进行i次比较的时候，时间复杂度为O(n^2)* 稳定性: 由于当两个元素相等时并不发生交换，所以冒泡排序是一个稳定的排序算法。*/public static void bubbleSort(int[] array)&#123; int temp; for (int i=0;i&lt;array.length-1;i++)&#123; for (int j=array.length-1;j&gt;i;j--)&#123; if(array[j]&lt;array[j-1])&#123; temp=array[j]; array[j]=array[j-1]; array[j-1]=temp; &#125; &#125; &#125;&#125; 快速排序快速排序是对冒泡排序的一种改进。其基本思想是基于分治法的。每次在待排序列表中找出一个元素pivot作为基准，通过一趟排序将待排序表划分为两个独立的部分，其中一边是全大于pivot的元素，而另一边则是全小于pivot的元素，这样递归的做下去，就可以使所有元素都放到其最终位置。具体的代码如下：123456789101112131415161718192021222324252627282930313233343536/*** 排序名称:快速排序* 空间效率:快速排序是递归的，需要借助一个递归的栈来保存每一层递归的信息。* 其容量应该与递归调用的最大深度是一致的。在最坏情况下，栈的深度是O(n)，而在平均情况下* 栈的深度为O(logN)* 时间效率: 快速排序的运行时间与划分是否对称有关系，在通常情况下，时间复杂* 度为O(nlogN)，而在最坏情况下则会达到O(n^2)* 稳定性: 划分算法中，若右端区间存在两个关键字相同，切均小于基准值的记录，则在* 交换到左端区间后，它们的相对位置会发生变化，也就是说快速排序是一个不稳定的排序算法。*/public static void quickSort(int[] array,int start,int end)&#123; if(start&lt;end)&#123; int pivotpos=partition(array,start,end); quickSort(array,start,pivotpos-1); quickSort(array,pivotpos+1,end); &#125;&#125;/*** 这是快速排序的辅助函数，用来找出每一次划分的位置，并且确定该划分元素在待排序列中的最终位置*/public static int partition(int[] array,int start,int end)&#123; int povit=array[start]; while (start&lt;end)&#123; while (start&lt;end&amp;&amp;array[end]&gt;=povit) &#123; --end; &#125; array[start]=array[end]; while (start&lt;end&amp;&amp;array[start]&lt;=povit)&#123; ++start; &#125; array[end]=array[start]; &#125; array[start]=povit; return start;&#125; 选择排序选择排序的基本思想是：每一趟(例如第i趟)在后面n-i+1个待排序元素中选择关键字最小的元素，作为有序子序列的第i个元素，直到第n-1趟做完，待排序元素只剩下1个就不用再选了。 简单选择排序简单选择排序的基本思想是：假设排序表为L[1…n],第i趟排序即从L[i…n]中选择关键字最小的元素与L(i)交换，每一趟排序可以确定一个元素的位置，这样经过n-1趟排序就可以使整个排序表有序。123456789101112131415161718192021/*** 排序名称:简单选择排序* 空间效率:仅使用了常数个辅助单元，因而空间复杂度为O(1)* 时间效率: 简单选择排序中过程中，元素移动的操作次数很少，最好的情况下移动0次* 此时对应的表已经有序；但元素间比较的次数与序列的初始状态无关，时间复杂度始终是O(n^2)* 稳定性: 在第i趟找到最小元素后，和第i个元素交换，可能会导致第i个元素与其含有相同* 关键字元素的相对位置发生改变。简单选择是一个不稳定的排序算法。*/public static void selectSort(int[] array)&#123; for (int i=0;i&lt;array.length-1;i++)&#123; int min=i; for (int j=i+1;j&lt;array.length;j++)&#123; if (array[j]&lt;array[i]) min=j; &#125; if (min!=i)&#123; int temp=array[min]; array[min]=array[i]; array[i]=temp; &#125; &#125; &#125; 堆排序堆排序是一种树形选择排序算法，它的特点是:在排序过程中将待排序表看成是一个二叉树的顺序存储结构，利用完全二叉树中双亲节点和孩子节点之间的内在关系，在当前的无序区中选择关键字最大（或者最小）的元素。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/*** 堆排序*/private static void heapSort(int[] array) &#123; buildMaxHeap(array,array.length); // 逐步将每个最大值的根节点与末尾元素交换，并且再调整二叉树，使其成为大顶堆 for (int i = array.length - 1; i &gt; 0; i--) &#123; swap(array, 0, i); // 将堆顶记录和当前未经排序子序列的最后一个记录交换 heapAdjust(array, 0, i); // 交换之后，需要重新检查堆是否符合大顶堆，不符合则要调整 &#125;&#125;/*** 初始化一个大顶堆* @param array* @param len*/public static void buildMaxHeap(int[] array,int len)&#123; for (int i=len/2;i&gt;=0;i--)&#123; heapAdjust(array,i,len); &#125;&#125;/*** 构建堆的过程* @param arr 需要排序的数组* @param i 需要构建堆的根节点的序号* @param n 数组的长度*/private static void heapAdjust(int[] arr, int i, int n) &#123; int child; int father; for (father = arr[i]; leftChild(i) &lt; n; i = child) &#123; child = leftChild(i); // 如果左子树小于右子树，则需要比较右子树和父节点 if (child != n - 1 &amp;&amp; arr[child] &lt; arr[child + 1]) &#123; child++; // 序号增1，指向右子树 &#125; // 如果父节点小于孩子结点，则需要交换 if (father &lt; arr[child]) &#123; arr[i] = arr[child]; &#125; else &#123; break; // 大顶堆结构未被破坏，不需要调整 &#125; &#125; arr[i] = father;&#125;// 获取到左孩子结点private static int leftChild(int i) &#123; return 2 * i + 1;&#125;// 交换元素位置private static void swap(int[] arr, int index1, int index2) &#123; int tmp = arr[index1]; arr[index1] = arr[index2]; arr[index2] = tmp;&#125; 归并排序归并排序与上述的交换，选择等排序的思想是不一样的。归并的意义是将两个或者两个以上的有序表组成一个新的有序表。通过递归的方法来完成整个排序的操作。1234567891011121314151617181920212223242526272829303132333435/*** 排序名称:归并排序* 空间效率:merge操作中，辅助空间要占用n个单元，空间复杂度为O(n)* 时间效率: 每一趟归并的时间复杂度为O(n),算法的时间复杂度为O(n*logN)* 稳定性: 由于merge操作不会改变相同关键字记录的相对次序，所以二路归并排序算法是一个* 稳定的算法*/public static void mergeSort(int[] array,int start,int end)&#123; if (start&lt;end)&#123; int mid=(start+end)/2; mergeSort(array,start,mid); mergeSort(array,mid+1,end); merge(array,start,mid,end); &#125;&#125;/*** 归并排序的辅助函数，作用是将两个有序的数组合并到同一个数组中去*/public static void merge(int[] array,int start,int mid,int end)&#123; int i,j,k; int[] tempArray=new int[array.length]; for (i=0;i&lt;array.length;i++)&#123; tempArray[i]=array[i]; &#125; for (i=start,j=mid+1,k=start;i&lt;=mid&amp;&amp;j&lt;=end;k++)&#123; if(tempArray[i]&lt;tempArray[j])&#123; array[k]=tempArray[i++]; &#125;else &#123; array[k]=tempArray[j++]; &#125; &#125; while (i&lt;=mid) array[k++]=tempArray[i++]; while (j&lt;=end) array[k++]=tempArray[j++];&#125;]]></content>
      <categories>
        <category>数据结构</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java实现图的存储与基本操作]]></title>
    <url>%2F2016%2F09%2F26%2FJava%E5%AE%9E%E7%8E%B0%E5%9B%BE%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[概述今天花了点时间，将数据结构中比较经典的图的基本应用用Java实现了一下，记录一下。因为觉得图的数据结构是比较经典的。其实，主要是好像面试似乎会弄得很多。准备一点也好。数据结构里面，图的存储方式其实是有很多的。在以前考408的时候，复习了的就有四种，分别是邻接矩阵法，邻接表法，十字链表法和邻接多重法。不过今天只准备实现两种最常用的邻接矩阵和邻接表法。因为这两种是用的最频繁的，难度其实也比另外两种小。 邻接矩阵所谓的邻接矩阵存储，就是用一个一维数组来存储图中顶点的信息，而用一个二维数据存储图中边的信息(也就是各个顶点之间的邻接关系)，存储顶点之间邻接关系的二维数组称之为邻接矩阵。以下用一个无向图的邻接矩阵作为示例: 很明显的能看出来该无向图的邻接矩阵是一个对称矩阵。其实这也是很好理解的。从V0到V1有距离必然意味着V1到V0是有距离的。 而有向图的邻接矩阵可看如下图所示: 可以看出来有向图其实并不是对称的。另外如果这个有向图是有权值的话，矩阵中的数字1也是可以替换成其他的数字的。 我写了一个AMGraph的实现类，主要是邻接矩阵的生成初始化以及简单的插入删除边和节点的操作。 1234567891011121314151617181920212223242526272829303132333435363738import java.util.*;/** * @author WorthyYao * @date 2016/9/26 */public class AMGraph &#123; private ArrayList vertexList; private int[][] edges; private int numsEdge; //初始化邻接矩阵 public AMGraph(int n)&#123; edges=new int[n][n]; vertexList=new ArrayList(n); numsEdge=0; &#125; //返回图中点的数目 public int getNumOfVertix()&#123; return vertexList.size(); &#125; //返回图中边的条数 public int getNumOfEdge()&#123; return numsEdge; &#125; //增加图中的点 public void insertVertex(Object vertex) &#123; vertexList.add(vertexList.size(),vertex); &#125; //在图中插入一条边 public void insertEdge(int v1,int v2,int weight)&#123; edges[v1][v2]=weight; numsEdge++; &#125; //在图中删除一条边 public void removeVertix(int v1,int v2)&#123; edges[v1][v2]=0; numsEdge--; &#125;&#125; 邻接表在一个图是稀疏图的时候，使用邻接矩阵来表示一个图其实是很浪费存储空间的。咋办，邻接表法主要就是用来解决这个问题的。所谓的邻接表，其实是将图中所有顶点组合起来做成一个单链表。而第i个单链表中的结点则表示依附于顶点Vi的边，这样的链表就可以称之为顶点Vi的边表。比如上面那个无向图的邻接表就可以如下所示: 实现给出一个有向图如下所示，可以写出他的邻接矩阵和邻接表的实现方法以及邻接矩阵的插入删除操作。 12345678910111213141516171819202122232425/** * @author WorthyYao * @date 2016/9/26 */public class Main &#123; public static void main(String[] args) &#123; //初始化图 AMGraph amg=new AMGraph(4); //初始化四个节点 String[] vertexs=&#123;"v1","v2","v3","v4"&#125;; for (int i=0;i&lt;vertexs.length;i++)&#123; amg.insertVertex(vertexs[i]); &#125; //插入四条边 amg.insertEdge(0,1,2); amg.insertEdge(0,2,5); amg.insertEdge(2,3,8); amg.insertEdge(3,0,7); System.out.println("图中顶点数为: "+amg.getNumOfVertix()); System.out.println("图中边的数目为: "+amg.getNumOfEdge()); amg.removeVertix(2,3); System.out.println("在删除一条边后的总边数为: "+amg.getNumOfEdge()); &#125;&#125; 运行结果如下: 而邻接表的矩阵初始化则如下代码所示: 1234567891011121314151617181920212223242526272829303132333435363738394041/** * @author WorthyYao * @date 2016/9/26 *///邻接表中表对应的链表的结构class Enode&#123; //初始化邻接表中顶点的名称以及值 String vertex; int value; Enode next;&#125;class Vnode&#123; String vertex; Enode firstEdge;&#125;//邻接表中图的存储public class ALGraph &#123; public static void main(String[] args) &#123; String[] vertexs=&#123;"v1","v2","v3","v4"&#125;; Vnode[] vers=new Vnode[vertexs.length]; //初始化链表 for(int i=0;i&lt;vertexs.length;i++)&#123; vers[i].vertex=vertexs[i]; vers[i].firstEdge=null; &#125; //插入几条边，初始化邻接表图 Enode node1=new Enode(); Enode node2=new Enode(); Enode node3=new Enode(); Enode node4=new Enode(); node1.vertex="v2";node1.value=2; node2.vertex="v2";node2.value=5; node3.vertex="v4";node1.value=8; node4.vertex="v1";node1.value=7; vers[0].firstEdge=node1; node1.next=node2; vers[2].firstEdge=node3; vers[3].firstEdge=node4; &#125;&#125;]]></content>
      <categories>
        <category>数据结构</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[迁移到coding.net]]></title>
    <url>%2F2016%2F09%2F22%2F%E8%BF%81%E7%A7%BB%E5%88%B0coding.net%2F</url>
    <content type="text"><![CDATA[博客已经弄了很久了，不过一直更新的不多。除了最近的事情多以外，很大的一个原因就是博客以前是放在ConoHa上面的。国内的访问速度一直不太好,打开就要很久。最近因为项目的原因用到了coding.net。国内的感觉还不错。而且他也提供pages服务。索性就决定放到这边来了。而且把域名绑定到这边的pages上面来。用过之后感觉速度还是蛮好的。以后如果没有什么大的变动的话，就在这安个小窝了，嘿嘿。已经快要十月了。事情真的是很多。论文，做实验，项目，找工作。所有的事情，似乎都一瞬间压上来了。好在與情分析这个项目暂时已经可以脱身了，赶快去把lab的事情做好吧。加油！]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>Life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[與情分析的爬虫]]></title>
    <url>%2F2016%2F07%2F28%2F%E8%88%87%E6%83%85%E5%88%86%E6%9E%90%E7%9A%84%E7%88%AC%E8%99%AB%2F</url>
    <content type="text"><![CDATA[暑假的任务里面有一个與情分析。这两天我爬取了一些数据准备在后面的时候用到。因为是高校的與情分析，数据的获取其实是一个蛮忧伤的事情。最后想了半天还是决定从百度新闻上面搜索到的新闻的价值可能会比较高一点。数据来源清晰后还有一个问题就是怎么直接抽取网页正文，我在试用了BeautifulSoup和xpath都没有找到满意的解决方案时，无意中找到了两个python的处理网页的库，感觉还是很不错的。推荐一下，分别就是readability-lxml和html2text。看一下他们的官方例子。readability的：1234from readability.readability importDocument import urllib html = urllib.urlopen(url).read()readable_article = Document(html).summary()readable_title = Document(html).short_title() html2text的12# -*- coding: utf-8 -*- import html2textprint html2text.html2text(u'&lt;html&gt;&lt;body&gt;&lt;div&gt;&lt;div class="note" id="link-report"&gt;&lt;p&gt;（1）网页去噪&lt;/p&gt;&lt;p&gt;网页去噪需要去掉与网页内表达内容不相关的文字，如广告，评论等等。现在对于博客、新闻类的网页去噪已经有很多的应用，比如常用的印象笔记、有道笔记就用到了相关的技术。&lt;/p&gt;&lt;p&gt;因为项目的需要，也需要对网页进行去噪，留下有用的内容。所以在网上找了相关的网页去噪的开源项目。&lt;/p&gt;&lt;p&gt;（2）参考链接&lt;/p&gt;&lt;p&gt;主要参考的链接是这篇“网页正文抽取工具”， 应该是抓取的新浪weibo上的相关的微博内容。里面介绍了给出了项目的地址，有Java、C++、C#、Perl、Python的。&lt;/p&gt;&lt;p&gt;因为项目是Python写的，所以初步选定使用 Decruft ， Python readability ， Python boilerpipe ，Pyhon Goose这几种。&lt;/p&gt;&lt;p&gt;（3）实践操作&lt;/p&gt;&lt;p&gt;Python readability的使用：&lt;/p&gt;&lt;p&gt;from readability.readability import Document&lt;/p&gt;&lt;p&gt;import urllib&lt;/p&gt;&lt;p&gt;html = urllib.urlopen(url).read()&lt;/p&gt;&lt;p&gt;readable_article = Document(html).summary()&lt;/p&gt;&lt;p&gt;readable_title = Document(html).short_title()&lt;/p&gt;&lt;p&gt;最后抽取出来的readable_article是带HTML标签的文本。还需要进行clean html操作。如果需要得到纯文本内容，还需要做其他工作&lt;/p&gt;&lt;p&gt;“decruft is a fork of python-readability to make it faster. It also has some logic corrections and improvements along the way.” （引自：&lt;/p&gt;&lt;a rel="nofollow" href="http://www.minvolai.com/blog/decruft-arc90s-readability-in-python/" target="_blank"&gt;http://www.minvolai.com/blog/decruft-arc90s-readability-in-python/&lt;/a&gt;&lt;p&gt;）&lt;/p&gt;&lt;p&gt;decruft是Python readability的fork版本，其主要提高了readability的速度。decruft的源码是放在Goolge上的，发现他只有0.1版本，而且是10年9月的，但是Python-readability一直在更新的，其核心的readability.py是7个月前更新的，所以不能保证decruft的性能要比现在的readability好，我没有下载decruft进行试验，有兴趣可以自己试验一下。&lt;/p&gt;&lt;p&gt;Python-boilerpipe：是Boilerpipe的Python版本的Warpper，在使用的时候需要依赖jpype, chardet. 在构造Extractor的时候可以定制自己需要的抽取器，具体有：&lt;/p&gt;&lt;p&gt;DefaultExtractor&lt;/p&gt;&lt;p&gt;ArticleExtractor&lt;/p&gt;&lt;p&gt;ArticleSentencesExtractor&lt;/p&gt;&lt;p&gt;KeepEverythingExtractor&lt;/p&gt;&lt;p&gt;KeepEverythingWithMinKWordsExtractor&lt;/p&gt;&lt;p&gt;LargestContentExtractor&lt;/p&gt;&lt;p&gt;NumWordsRulesExtractor&lt;/p&gt;&lt;p&gt;CanolaExtractor&lt;/p&gt;&lt;p&gt;这个项目可以自己选择抽取出的正文内容格式：可以是纯文本的，也可以是携带HTML的。&lt;/p&gt;&lt;p&gt;Python-Goose：&lt;/p&gt;&lt;p&gt;经过试验，决定使用Goose，可以在这个网址上测试 &lt;/p&gt;&lt;a rel="nofollow" href="http://jimplush.com/blog/goose" target="_blank"&gt; http://jimplush.com/blog/goose&lt;/a&gt;&lt;p&gt; Goose的抽取效果。Goose还能够获得Meta description。&lt;/p&gt;&lt;p&gt;Goose最后可以获得抽取后的纯文本。&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;') 在结合了这两个一起使用之后，感觉拿下来的抽取网页正文效果是不错的。代码如下。123456789101112131415161718192021222324252627282930313233343536373839404142434445# -*- coding: utf-8 -*-import urllib2import sysimport refrom readability import Documentimport html2textimport timeimport os#设置编码为utf-8reload(sys)sys.setdefaultencoding( "utf-8" )user_agent = 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'headers = &#123; 'User-Agent' : user_agent &#125;base_url="http://news.baidu.com/ns?word=&#123;school&#125;&amp;pn=&#123;number&#125;&amp;rn=20"school_list=['上海交通大学','同济大学','复旦大学','华东师范大学','上海大学','华东理工大学','东华大学','上海财经大学','上海外国语大学','华东政法大学','上海师范大学','上海理工大学','上海海事大学','上海海洋大学','上海中医药大学','上海体育学院','上海音乐学院','上海戏剧学院','上海对外经贸大学','上海电机学院','上海工程技术大学','上海科技大学','大连海事大学','武汉理工大学','广西航运学院','武汉交通科技大学','集美大学','南通海校','中国海洋大学']for school in school_list: os.mkdir(school) count=0 for i in range(0,401,20): url=base_url.format(school=school,number=i) print url time.sleep(4) try: request=urllib2.Request(url,headers=headers) html=urllib2.urlopen(request).read() re_result=r'&lt;div class="result" .*?&gt;(.*?)&lt;/div&gt;' re_href=r'&lt;a href="(.*?)"' result=re.findall(re_result,html,re.S|re.M) for detail in result: href=re.findall(re_href,detail,re.S|re.M)[0] time.sleep(1) try: html=urllib2.urlopen(href,timeout=5).read() readable_article = Document(html).summary() result=html2text.html2text(readable_article) print "processing...." with open(school+"/"+str(count)+".txt","w") as f: f.write(result) count=count+1 except Exception,e: print e]]></content>
      <categories>
        <category>It</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>與情分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 077 Combinations]]></title>
    <url>%2F2016%2F07%2F25%2FLeetCode-077-Combinations%2F</url>
    <content type="text"><![CDATA[Given two integers n and k, return all possible combinations of k numbers out of 1 … n. For example,If n = 4 and k = 2, a solution is: [ [2,4], [3,4], [2,3], [1,2], [1,3], [1,4],] 被这道题坑了超级长的时间。题目很长时间内都没有看明白。我把中间的诸如[2,4]以为是从2到4.我就觉得很奇怪，明明是挑出k个数，为什么挑出这么多数字来。就因为这个卡了好久的时间。这道题目又是一道深度优先搜索的问题，也就是回溯法的应用。说起来这种题目已经做了好几道了。慢慢的有点儿感觉，但还是需要多练习练习。123456789101112131415161718192021222324public class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; combine(int n, int k) &#123; List&lt;List&lt;Integer&gt;&gt; res=new ArrayList&lt;List&lt;Integer&gt;&gt;(); if(n&lt;=0||n&lt;k) return res; ArrayList&lt;Integer&gt; item=new ArrayList&lt;&gt;(); dfs(n,k,1,item,res); return res; &#125; private void dfs(int n,int k,int start,ArrayList&lt;Integer&gt; item,List&lt;List&lt;Integer&gt;&gt; res)&#123; if(item.size()==k)&#123; ArrayList&lt;Integer&gt; temp=new ArrayList&lt;Integer&gt;(item); res.add(temp); return; &#125; for (int i=start;i&lt;=n;i++)&#123; item.add(i); dfs(n,k,i+1,item,res); item.remove(item.size()-1); &#125; &#125;&#125;]]></content>
      <categories>
        <category>it</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 069 Sqrt(x)]]></title>
    <url>%2F2016%2F07%2F14%2FLeetCode-069-Sqrt-x%2F</url>
    <content type="text"><![CDATA[Implement int sqrt(int x). Compute and return the square root of x. 计算x的平方根。题目难度还好，有两个问题。第一个是普通的遍历的话时间是不够用的，二分法来做。 第二是注意题目给的是int型，做的时候要注意溢出的问题。所以用了long型。 1234567891011121314151617public class Solution &#123; public int mySqrt(int x) &#123; long start=1,end=x; while (start+1&lt;end)&#123; long mid=start+(end-start)/2; if(mid*mid&lt;=x)&#123; start=mid; &#125;else &#123; end=mid; &#125; &#125; if(end*end&lt;=x)&#123; return (int)end; &#125; return (int)start; &#125;&#125;]]></content>
      <categories>
        <category>it</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最后一个暑假来了]]></title>
    <url>%2F2016%2F07%2F05%2F%E6%9C%80%E5%90%8E%E4%B8%80%E4%B8%AA%E6%9A%91%E5%81%87%E6%9D%A5%E4%BA%86%2F</url>
    <content type="text"><![CDATA[这么长时间，上传的都是leetcode题目，稍微写点生活上的杂记吧。其实有一段时间没有更新了，主要是前段时间的考试比较多。另外还有一些lab的东西，似乎总是无法抽出身来去做一些别的事情，令人遗憾。考试结束了，生活还是规律一点吧。学生时代的最后一个暑假了，加油。]]></content>
      <categories>
        <category>life</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 064 Minimum Path Sum]]></title>
    <url>%2F2016%2F07%2F05%2FLeetCode-064-Minimum-Path-Sum%2F</url>
    <content type="text"><![CDATA[Given a m x n grid filled with non-negative numbers, find a path from top left to bottom right which minimizes the sum of all numbers along its path. Note: You can only move either down or right at any point in time. 这道题目是求在一个矩阵中的最短路径问题。和前面两道题目是非常像的，也是一个动态规划的问题。 这道题目的精髓是抽象出来sum[i][j]=grid[i][j]+min(sum[i-1][j],sum[i][j-1]),也就是说当前的最小值是需要根据当前值和上方最小值与左方最小值来共同决定。12345678910111213141516171819202122public class Solution &#123; public int minPathSum(int[][] grid) &#123; int m=grid.length; int n=grid[0].length; int[][] sum=new int[m][n]; sum[0][0]=grid[0][0]; for(int i=1;i&lt;m;i++)&#123; sum[i][0]=sum[i-1][0]+grid[i][0]; &#125; for(int i=1;i&lt;n;i++)&#123; sum[0][i]=sum[0][i-1]+grid[0][i]; &#125; for(int i=1;i&lt;m;i++)&#123; for(int j=1;j&lt;n;j++)&#123; sum[i][j]=grid[i][j]+Math.min(sum[i-1][j],sum[i][j-1]); &#125; &#125; return sum[m-1][n-1]; &#125;&#125;]]></content>
      <categories>
        <category>it</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 063 Unique Paths II]]></title>
    <url>%2F2016%2F07%2F04%2FLeetCode-063-Unique-Paths%2F</url>
    <content type="text"><![CDATA[Follow up for “Unique Paths”: Now consider if some obstacles are added to the grids. How many unique paths would there be? An obstacle and empty space is marked as 1 and 0 respectively in the grid. For example,There is one obstacle in the middle of a 3x3 grid as illustrated below. [ [0,0,0], [0,1,0], [0,0,0]]The total number of unique paths is 2.这道题目和前面的62是同一样的题目，所以就放在一起来写了。题目的意思是要找出机器人在一个m*n的矩阵中到达对角的所有可能。而63和62所不同的是，题目中设置了障碍，当遇到障碍的时候，这条路就是走不通的情况。题目的解决方法是用动态规划来解决的。如果能注意到，其中每个点的总路数其实是它的上面那个点的路数与左边路数之和。问题是好解决的。而在本道题目中，在遇到障碍的时候，将那一个具体格置为0即可。1234567891011121314151617181920212223242526272829303132333435public class Solution &#123; public int uniquePathsWithObstacles(int[][] obstacleGrid) &#123; int m=obstacleGrid.length; int n=obstacleGrid[0].length; int [][]path=new int[m][n]; for(int i=0;i&lt;m;i++)&#123; if(obstacleGrid[i][0]!=1)&#123; path[i][0]=1; &#125;else&#123; break; &#125; &#125; for(int i=0;i&lt;n;i++)&#123; if(obstacleGrid[0][i]!=1)&#123; path[0][i]=1; &#125;else&#123; break; &#125; &#125; for(int i=0;i&lt;m;i++)&#123; for(int j=0;j&lt;n;j++)&#123; if(obstacleGrid[i][j]==1)&#123; path[i][j]=0; &#125;else &#123; path[i][j]=path[i-1][j]+path[i][j-1]; &#125; &#125; &#125; return path[m-1][n-1]; &#125;&#125;]]></content>
      <categories>
        <category>it</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 060 Permutation Sequence]]></title>
    <url>%2F2016%2F06%2F30%2FLeetCode-060-Permutation-Sequence%2F</url>
    <content type="text"><![CDATA[The set [1,2,3,…,n] contains a total of n! unique permutations. By listing and labeling all of the permutations in order,We get the following sequence (ie, for n = 3): “123”“132”“213”“231”“312”“321”Given n and k, return the kth permutation sequence. 这道题和46,47题都很有关系的，但是那两道题目都是一个个的插入进去来做的。这道题目如果先排好序再来做的话，时间复杂度是o(n3)，明显是不可以的。 如果换用别的思路的话，可以发现的是如果给的是n个数，那么会有的是n！个组合。而第一个数是有(n-1)!个可能的。依次往下类推下去，可以得出这道题的解决办法。另外一点是用arraylist来保存数字，当这些数字被用过以后，就从arraylist中除掉。1234567891011121314151617181920212223public class Solution &#123; public String getPermutation(int n, int k) &#123; String res=""; ArrayList&lt;Integer&gt; number=new ArrayList&lt;&gt;(); for(int i=1;i&lt;=n;i++)&#123; number.add(i); &#125; k--; int temp=1; for(int i=1;i&lt;=n;i++)&#123; temp=temp*i; &#125; for (int i=0;i&lt;n;i++)&#123; temp=temp/(n-i); int index=k/temp; k=k%temp; res=res+number.get(index); number.remove(index); &#125; return res.toString(); &#125;&#125;]]></content>
      <categories>
        <category>it</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 059 Spiral Matrix II]]></title>
    <url>%2F2016%2F06%2F05%2F059-Spiral-Matrix-II%2F</url>
    <content type="text"><![CDATA[Given an integer n, generate a square matrix filled with elements from 1 to n2 in spiral order. For example,Given n = 3, You should return the following matrix:[ [ 1, 2, 3 ], [ 8, 9, 4 ], [ 7, 6, 5 ]] 螺旋矩阵第二道。不过并没有太大的新意。和第一道的思路基本是差不多的。就像剥洋葱，一层层的剥下去就可以了。1234567891011121314151617181920212223242526272829303132public class Solution &#123; public int[][] generateMatrix(int n) &#123; int[][] matrix=new int[n][n]; int x1=0, y1=0; int x2=n-1, y2=n-1; int temp=0; while (x1&lt;=x2&amp;&amp;y1&lt;=y2)&#123; for(int i=y1;i&lt;=y2;i++)&#123; temp++; matrix[x1][i]=temp; &#125; for(int i=x1+1;i&lt;=x2;i++)&#123; temp++; matrix[i][y2]=temp; &#125; if(x1!=x2)&#123; for(int i=y2-1;i&gt;=y1;i--)&#123; temp++; matrix[x2][i]=temp; &#125; &#125; if(y1!=y2)&#123; for(int i=x2-1;i&gt;x1;i--)&#123; temp++; matrix[i][y1]=temp; &#125; &#125; x1++;y1++;x2--;y2--; &#125; return matrix; &#125;&#125;]]></content>
      <categories>
        <category>it</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 058 Length of Last Word]]></title>
    <url>%2F2016%2F06%2F05%2FLeetCode-058-Length-of-Last-Word%2F</url>
    <content type="text"><![CDATA[Given a string s consists of upper/lower-case alphabets and empty space characters ‘ ‘, return the length of last word in the string. If the last word does not exist, return 0. Note: A word is defined as a character sequence consists of non-space characters only. For example,Given s = “Hello World”,return 5. 题目的意思是给出一个字符串，求出这个字符串的最后一个没有空格的完整的字符串。题目的难度还好，我想到的是从字符串的最后开始出发，先找到end在哪里。然后再找出start在哪里。最后返回两个的之差就可以了。我在做的时候，遇到的一个坑就是在判断end的时候，是判断的s.length!=’ ‘，给搞反了。123456789101112131415public class Solution &#123; public int lengthOfLastWord(String s) &#123; if(s.length()==0) return 0; int end=s.length()-1; while (end&gt;=0&amp;&amp;s.charAt(end)!=' ')&#123; end--; &#125; if(end==-1) return 0; int start=end; while (start&gt;=0&amp;&amp;s.charAt(start)!=' ')&#123; start--; &#125; return end-start; &#125;&#125;]]></content>
      <categories>
        <category>it</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 057 Insert Interval]]></title>
    <url>%2F2016%2F06%2F02%2FLeetCode-057-Insert-Interval%2F</url>
    <content type="text"><![CDATA[Given a set of non-overlapping intervals, insert a new interval into the intervals (merge if necessary). You may assume that the intervals were initially sorted according to their start times. Example 1:Given intervals [1,3],[6,9], insert and merge [2,5] in as [1,5],[6,9]. Example 2:Given [1,2],[3,5],[6,7],[8,10],[12,16], insert and merge [4,9] in as [1,2],[3,10],[12,16]. This is because the new interval [4,9] overlaps with [3,5],[6,7],[8,10]. 因为这道题目和56题大部分相同，就放在这一块写了。57题相较于56只是多了一个在list中插入Interval的操作。主要还是用到了merge函数的部分。主要的思路是先通过将list进行一次排序，然后再通过start和end的位置，来进行合并。这道题主要学习了comparator接口的使用。1234567891011121314151617181920212223242526272829303132333435363738public class Solution &#123; public List&lt;Interval&gt; insert(List&lt;Interval&gt; intervals, Interval newInterval) &#123; List&lt;Interval&gt; res=new ArrayList&lt;&gt;(); if(intervals.size()==0)&#123; res.add(newInterval); return res; &#125; intervals.add(newInterval); res=merge(intervals); return res; &#125; public List&lt;Interval&gt; merge(List&lt;Interval&gt; intervals) &#123; if(intervals==null||intervals.size()&lt;=1)&#123; return intervals; &#125; Collections.sort(intervals,new IntervalComparator()); List&lt;Interval&gt; res=new ArrayList&lt;Interval&gt;(); Interval last=intervals.get(0); for(int i=1;i&lt;intervals.size();i++)&#123; Interval curr=intervals.get(i); if(curr.start&lt;=last.end)&#123; last.end=Math.max(last.end,curr.end); &#125;else &#123; res.add(last); last=curr; &#125; &#125; res.add(last); return res; &#125; public class IntervalComparator implements Comparator&lt;Interval&gt;&#123; public int compare(Interval a,Interval b)&#123; return a.start-b.start; &#125; &#125;&#125;]]></content>
      <categories>
        <category>it</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 055 Jump Game(java)]]></title>
    <url>%2F2016%2F05%2F31%2FLeetCode-055-Jump-Game-java%2F</url>
    <content type="text"><![CDATA[Given an array of non-negative integers, you are initially positioned at the first index of the array. Each element in the array represents your maximum jump length at that position. Determine if you are able to reach the last index. For example:A = [2,3,1,1,4], return true. A = [3,2,1,0,4], return false. 这道题的要求是判断最后在给定的数组中能否走到最后的一个问题，解决思路是每走一步的时候判断是否越过界。时间复杂度为o(n). 12345678910111213public class Solution &#123; public boolean canJump(int[] nums) &#123; int max=nums[0]; for(int i=1;i&lt;nums.length;i++)&#123; if (max==0) return false; max--; if(nums[i]&gt;max)&#123; max=nums[i]; &#125; &#125; return true; &#125;&#125;]]></content>
      <categories>
        <category>it</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客上线]]></title>
    <url>%2F2016%2F05%2F29%2F%E5%8D%9A%E5%AE%A2%E4%B8%8A%E7%BA%BF%2F</url>
    <content type="text"><![CDATA[博客上线了，以后就在这里面写字吧。]]></content>
      <categories>
        <category>Life</category>
        <category>Testing</category>
      </categories>
      <tags>
        <tag>Testing</tag>
        <tag>Life</tag>
        <tag>Another Tag</tag>
      </tags>
  </entry>
</search>
